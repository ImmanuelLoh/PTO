{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de74bfa",
   "metadata": {},
   "source": [
    "Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b351d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdfplumber\n",
    "!pip install camelot-py[cv]\n",
    "!pip install --upgrade pymupdf\n",
    "!pip install google-generativeai\n",
    "!pip install faiss-cpu\n",
    "!pip install transformers tqdm pandas pytesseract pillow easyocr langchain langchain-community langchain_openai faiss-cpu rank_bm25 pdf2image\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c843b2",
   "metadata": {},
   "source": [
    "Imports and set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9178ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import os, glob\n",
    "import pdfplumber\n",
    "import camelot\n",
    "import pymupdf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import faiss, json\n",
    "import collections\n",
    "import fitz\n",
    "import io\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df5255b",
   "metadata": {},
   "source": [
    "# Agent CFO — Performance Optimization & Design\n",
    "\n",
    "---\n",
    "This is the starter notebook for your project. Follow the required structure below.  \n",
    "\n",
    "You will design and optimize an Agent CFO assistant for a listed company. The assistant should answer finance/operations questions using RAG (Retrieval-Augmented Generation) + agentic reasoning, with response time (latency) as the primary metric.\n",
    "\n",
    "Your system must:\n",
    "*   Ingest the company’s public filings.\n",
    "*   Retrieve relevant passages efficiently.\n",
    "*   Compute ratios/trends via tool calls (calculator, table parsing).\n",
    "*   Produce answers with valid citations to the correct page/table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbdc036",
   "metadata": {},
   "source": [
    "## 1. Config & Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe90724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "# os.environ['GEMINI_API_KEY'] = 'your-key-here'\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-key-here'\n",
    "\n",
    "COMPANY_NAME = \"Google\"\n",
    "\n",
    "def generate_test_log_path_name(base_path: str): \n",
    "    # create the directory if not exist \n",
    "    os.makedirs(base_path, exist_ok=True) \n",
    "    existing_files = [f for f in os.listdir(base_path) if f.startswith(\"test_\") and f.endswith(\".json\")] \n",
    "    existing_indices = [int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()] \n",
    "    next_index = max(existing_indices) + 1 if existing_indices else 1 \n",
    "\n",
    "    return f\"{base_path}/test_{next_index}.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e284fa",
   "metadata": {},
   "source": [
    "## 2. Data Download (Dropbox)\n",
    "\n",
    "*   Annual Reports: last 3–5 years.\n",
    "*   Quarterly Results Packs & MD&A (Management Discussion & Analysis).\n",
    "*   Investor Presentations and Press Releases.\n",
    "*   These files must be submitted later as a deliverable in the Dropbox data pack.\n",
    "*   Upload them under `/content/data/`.\n",
    "\n",
    "Scope limit: each team will ingest minimally 15 PDF files total.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"00-data\"\n",
    "\n",
    "# Annual reports (10-Ks)\n",
    "annual_files = glob.glob(f\"{DATA_DIR}/annuals/*.pdf\")\n",
    "\n",
    "# # Quarterly reports (10-Qs)\n",
    "quarterly_files = glob.glob(f\"{DATA_DIR}/quarterlies/*.pdf\")\n",
    "\n",
    "# # Press releases\n",
    "# press_files = glob.glob(f\"{DATA_DIR}/press_releases/*.pdf\")\n",
    "\n",
    "# Presentations\n",
    "presentation_files = glob.glob(f\"{DATA_DIR}/presentations/*.pdf\")\n",
    "\n",
    "# Supplements\n",
    "supplement_files = glob.glob(f\"{DATA_DIR}/supplements/*.pdf\")\n",
    "\n",
    "# # Transcripts\n",
    "# transcript_files = glob.glob(f\"{DATA_DIR}/transcripts/*.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for folder in [\"annuals\", \"quarterlies\", \"press_releases\", \"presentations\", \"supplements\", \"transcripts\"]:\n",
    "for folder in [\"annuals\", \"quarterlies\", \"presentations\", \"supplements\"]:\n",
    "\n",
    "    files = glob.glob(f\"{DATA_DIR}/{folder}/*.pdf\")\n",
    "    print(f\"{folder}: {len(files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150a083",
   "metadata": {},
   "source": [
    "## 3. System Requirements\n",
    "\n",
    "**Retrieval & RAG**\n",
    "*   Use a vector index (e.g., FAISS, LlamaIndex) + a keyword filter (BM25/ElasticSearch).\n",
    "*   Citations must include: report name, year, page number, section/table.\n",
    "\n",
    "**Agentic Reasoning**\n",
    "*   Support at least 3 tool types: calculator, table extraction, multi-document compare.\n",
    "*   Reasoning must follow a plan-then-act pattern (not a single unstructured call).\n",
    "\n",
    "**Instrumentation**\n",
    "*   Log timings for: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total.\n",
    "*   Log: tokens used, cache hits, tools invoked.\n",
    "*   Record p50/p95 latencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f4e0c",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccde792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# load E5-base-v2\n",
    "model = SentenceTransformer(\"intfloat/e5-base-v2\")\n",
    "\n",
    "def embed_text_query(s):\n",
    "    # E5 expects prefix, and stripping/normalizing helps\n",
    "    return model.encode(f\"query: {s.strip().lower()}\", normalize_embeddings=True)\n",
    "\n",
    "def embed_text_passage(s) -> np.ndarray :\n",
    "    \"\"\"\n",
    "    It returns a numpy ndarray of shape (len(s), embedding_dimension)\n",
    "    [\n",
    "        [0.012, -0.034, 0.089, ..., -0.045],   # embedding for passage 1\n",
    "        [0.077,  0.120, -0.002, ...,  0.031],  # embedding for passage 2\n",
    "        [0.050, -0.025,  0.061, ..., -0.018]   # embedding for passage 3\n",
    "  ]\n",
    "    \"\"\"\n",
    "    # E5 expects prefix, and stripping/normalizing helps\n",
    "    return model.encode([f\"passage: {chunk_text.strip().lower()}\" for chunk_text in s],\n",
    "                        convert_to_numpy=True,\n",
    "                        normalize_embeddings=True,\n",
    "                        show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b8f6a",
   "metadata": {},
   "source": [
    "### Ingestion pipeline (Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74126a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert table ingestion code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639930d",
   "metadata": {},
   "source": [
    "### Ingestion pipeline (Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd09a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helpers ---\n",
    "def clean_table(table):\n",
    "    \"\"\"Clean raw Camelot table output.\"\"\"\n",
    "    print (\"Raw table:\", table)\n",
    "    return [\n",
    "        [(cell or \"\").strip().replace(\"\\n\", \" \") for cell in row]\n",
    "        for row in table\n",
    "    ]\n",
    "\n",
    "def _normalize(s: str) -> str:\n",
    "    s = (s or \"\").lower()\n",
    "    # unify whitespace & quotes\n",
    "    s = s.replace(\"\\n\", \" \").replace(\"’\", \"'\").replace(\"–\", \"-\").replace(\"—\", \"-\")\n",
    "    s = \" \".join(s.split())\n",
    "    return s\n",
    "\n",
    "\n",
    "def is_valid_table(table, numeric_threshold: float = 0.25) -> bool:\n",
    "    \"\"\"Return True if the table has enough numeric-looking cells to be considered real data.\"\"\"\n",
    "    if not table or not table[0]:\n",
    "        return False\n",
    "\n",
    "    cells = sum(len(r) for r in table)\n",
    "    numeric_cells = 0\n",
    "    num_pattern = re.compile(r\"^\\(?[+-]?\\d[\\d,\\.]*\\)?$\")  # matches 5,439 or (1,200) etc.\n",
    "\n",
    "    for row in table:\n",
    "        for cell in row:\n",
    "            cell = str(cell).strip().replace(\"$\", \"\").replace(\"%\", \"\")\n",
    "            if num_pattern.match(cell):\n",
    "                numeric_cells += 1\n",
    "\n",
    "    return (numeric_cells / cells) >= numeric_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "SECTION_EXAMPLES = {\n",
    "    # --- Cover / Administrative ---\n",
    "    \"cover_page\": [\n",
    "        \"united states securities and exchange commission form 10 k annual report pursuant to section 13 or 15d\",\n",
    "        \"united states securities and exchange commission form 10 q quarterly report pursuant to section 13 or 15d\",\n",
    "        \"cover page showing registrant name commission file number and state of incorporation\",\n",
    "        \"front page identifying registrant address telephone number and fiscal year end\",\n",
    "    ],\n",
    "\n",
    "    # --- Management Discussion ---\n",
    "    \"mdna\": [\n",
    "        \"managements discussion and analysis of financial condition and results of operations\",\n",
    "        \"md&a explaining liquidity capital resources and operating performance\",\n",
    "        \"discussion and analysis of results of operations comparing current and prior periods\",\n",
    "        \"analysis of changes in revenues costs cash flows and capital expenditures\",\n",
    "    ],\n",
    "\n",
    "    # --- Risk Factors ---\n",
    "    \"risk_factors\": [\n",
    "        \"risk factors that may affect future financial performance or share price\",\n",
    "        \"discussion of material risks and uncertainties facing the company\",\n",
    "        \"factors that could cause actual results to differ materially from forward looking statements\",\n",
    "    ],\n",
    "\n",
    "    # --- Financial Highlights / Summary Data ---\n",
    "    \"summary_financial_data\": [\n",
    "        \"selected financial data summarizing key performance indicators for the past five years\",\n",
    "        \"summary of consolidated financial information and operating results\",\n",
    "        \"selected financial highlights including revenue net income and earnings per share\",\n",
    "    ],\n",
    "\n",
    "    # --- Income Statement ---\n",
    "    \"income_statement\": [\n",
    "        \"consolidated statements of income showing revenue expenses and net income\",\n",
    "        \"statement of operations or profit and loss reporting revenues and operating income\",\n",
    "        \"consolidated statements of comprehensive income including other comprehensive income items\",\n",
    "        \"income statement presenting total revenues cost of goods sold gross profit and net earnings\",\n",
    "    ],\n",
    "\n",
    "    # --- Balance Sheet ---\n",
    "    \"balance_sheet\": [\n",
    "        \"consolidated balance sheets showing assets liabilities and shareholders equity\",\n",
    "        \"statement of financial position listing current assets long term liabilities and total equity\",\n",
    "        \"balance sheet detailing cash accounts receivable inventories property plant and equipment\",\n",
    "    ],\n",
    "\n",
    "    # --- Cash Flow Statement ---\n",
    "    \"cash_flow\": [\n",
    "        \"consolidated statements of cash flows showing cash inflows and outflows from operating investing and financing activities\",\n",
    "        \"statement of cash flows reconciling net income to net cash provided by operating activities\",\n",
    "        \"cash flow statement detailing capital expenditures debt repayment and dividend payments\",\n",
    "    ],\n",
    "\n",
    "    # --- Shareholders’ Equity ---\n",
    "    \"equity\": [\n",
    "        \"consolidated statements of shareholders equity showing changes in retained earnings dividends and stock issuance\",\n",
    "        \"statement of changes in stockholders equity presenting share repurchases and comprehensive income\",\n",
    "        \"equity statement showing common stock treasury stock retained earnings and accumulated other comprehensive income\",\n",
    "    ],\n",
    "\n",
    "    # --- Notes to Financial Statements ---\n",
    "    \"financial_statements\": [\n",
    "        \"notes to consolidated financial statements providing accounting policies commitments contingencies and segment information\",\n",
    "        \"footnotes accompanying consolidated financial statements describing significant accounting policies\",\n",
    "        \"notes to financial statements detailing income taxes stock compensation and earnings per share\",\n",
    "        \"supplementary information supporting consolidated financial statements\",\n",
    "    ],\n",
    "\n",
    "    # --- Market Risk Disclosures ---\n",
    "    \"market_risk_disclosures\": [\n",
    "        \"quantitative and qualitative disclosures about market risk\",\n",
    "        \"discussion of exposure to interest rate foreign currency commodity and credit risk\",\n",
    "        \"sensitivity analysis of market risk instruments\",\n",
    "    ],\n",
    "\n",
    "    # --- Controls and Procedures ---\n",
    "    \"controls_procedures\": [\n",
    "        \"controls and procedures section discussing disclosure controls and internal control over financial reporting\",\n",
    "        \"evaluation of disclosure controls and procedures and changes in internal control\",\n",
    "        \"managements report on internal control over financial reporting\",\n",
    "    ],\n",
    "\n",
    "    # --- Legal Proceedings ---\n",
    "    \"legal_proceedings\": [\n",
    "        \"description of material pending legal proceedings and litigation\",\n",
    "        \"legal proceedings section detailing lawsuits claims and regulatory actions\",\n",
    "        \"information about legal matters affecting the company\",\n",
    "    ],\n",
    "\n",
    "    # --- Segment Information ---\n",
    "    \"segment_info\": [\n",
    "        \"segment information describing operating segments geographic areas and major customers\",\n",
    "        \"disclosure of business segments including revenue and profit by segment\",\n",
    "        \"note providing details of segment performance and intersegment eliminations\",\n",
    "    ],\n",
    "\n",
    "    # --- Signatures ---\n",
    "    \"signatures\": [\n",
    "        \"signatures section signed on behalf of the registrant and principal officers\",\n",
    "        \"signatures of directors executive officers and principal accounting officer\",\n",
    "        \"signed by the registrant pursuant to the securities exchange act of 1934\",\n",
    "    ],\n",
    "\n",
    "    # --- Exhibits ---\n",
    "    \"exhibits\": [\n",
    "        \"exhibits and financial statement schedules\",\n",
    "        \"list of exhibits and certifications required by form 10k or 10q\",\n",
    "        \"exhibit index listing contracts and subsidiary information\",\n",
    "    ],\n",
    "\n",
    "    # --- Fallback ---\n",
    "    \"other\": [\n",
    "        \"miscellaneous sections not classified elsewhere including general disclosures appendices or cover letters\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf017aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SECTION_EMBS = {\n",
    "    sec: [embed_text_query(ex) for ex in examples]\n",
    "    for sec, examples in SECTION_EXAMPLES.items()\n",
    "}\n",
    "\n",
    "\n",
    "def classify_section(text, table):\n",
    "    page_text = _normalize(text)\n",
    "    headers = _normalize(\" \".join(table[0])) if table else \"\"\n",
    "    first_col = _normalize(\" \".join(row[0] for row in table[1:])) if table else \"\"\n",
    "\n",
    "    combined = f\"{page_text} {headers} {first_col}\"\n",
    "    emb = embed_text_query(combined)\n",
    "\n",
    "    scores = {\n",
    "        sec: max(util.cos_sim(emb, e).item() for e in embs)\n",
    "        for sec, embs in SECTION_EMBS.items()\n",
    "    }\n",
    "\n",
    "    best = max(scores, key=scores.get)\n",
    "    return best if scores[best] > 0.35 else \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d59bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = []\n",
    "for folder in [\"annuals\", \"quarterlies\", \"supplements\"]:\n",
    "    files = glob.glob(f\"{DATA_DIR}/{folder}/*.pdf\")\n",
    "    pdf_path.extend(files)\n",
    "\n",
    "print(f\"Processing {len(pdf_path)} PDFs from all folders\")\n",
    "print(\"PDF paths:\", pdf_path[:3], \"...\")\n",
    "\n",
    "# keep track sections\n",
    "sections = {}\n",
    "output = {}\n",
    "\n",
    "for pdfFile in pdf_path:\n",
    "    pdf_name = os.path.basename(pdfFile)\n",
    "    output[pdf_name] = {}\n",
    "\n",
    "    print(f\"\\n=== Processing: {pdf_name} ===\")\n",
    "\n",
    "    # Step 1: extract raw text with pdfplumber\n",
    "    with pdfplumber.open(pdfFile) as pdf:\n",
    "        for i, page in enumerate(pdf.pages, start=1):\n",
    "            text = page.extract_text() or \"\"\n",
    "            section_text = classify_section(text, [[]])  # classifying page text only without tables\n",
    "            sections[section_text] = sections.get(section_text, 0) + 1\n",
    "\n",
    "            # Step 2: extract tables\n",
    "            tables_pymupdf = extract_tables_from_page(pdfFile, i)\n",
    "\n",
    "            tables = []\n",
    "            for t in tables_pymupdf:\n",
    "                df = t[\"dataframe\"]\n",
    "                raw_table = df.values.tolist()\n",
    "\n",
    "                # if not is_valid_table(raw_table):\n",
    "                #     # Skip tables that are mostly text, like footnotes or headers\n",
    "                #     print(f\"[SKIP] Page {i} – Non-numeric table filtered out\")\n",
    "                #     continue\n",
    "\n",
    "                cleaned_table = clean_table(raw_table)\n",
    "                section_table = classify_section(text, cleaned_table)\n",
    "\n",
    "                # Track section counts\n",
    "                sections[section_table] = sections.get(section_table, 0) + 1\n",
    "\n",
    "                # Skip noise like signatures\n",
    "                if section_table == \"other\" and \"signature\" in text.lower():\n",
    "                    continue\n",
    "\n",
    "                markdown_text = pd.DataFrame(cleaned_table).to_markdown(index=False)\n",
    "\n",
    "                tables.append({\n",
    "                    \"section\": section_table,\n",
    "                    \"header\" : cleaned_table[0] if cleaned_table else [],\n",
    "                    \"rows\" : cleaned_table[1:] if len(cleaned_table) > 1 else [],\n",
    "                    \"markdown\": markdown_text\n",
    "                })\n",
    "\n",
    "            print(f\"Page {i} → Text length: {len(text) if text else 0}, Tables Kept: {len(tables)}\")\n",
    "\n",
    "            output[pdf_name][i] = {\n",
    "                \"page_section\": section_text,\n",
    "                \"text\": text,\n",
    "                \"tables\": tables\n",
    "            }\n",
    "\n",
    "print (\"Section distribution:\", sections)\n",
    "\n",
    "# Step 3: Create directory if it doesn't exist and dump to JSON\n",
    "output_path = f\"{DATA_DIR}/test.json\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(output, f, indent=4)\n",
    "\n",
    "print(f\"\\nOutput saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b970120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create directory if it doesn't exist and dump to JSON\n",
    "output_path = f\"{DATA_DIR}/test.json\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(output, f, indent=4)\n",
    "\n",
    "print(f\"\\nOutput saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf610cc",
   "metadata": {},
   "source": [
    "### Ingestion pipeline (Slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb3e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_slides_fitz(pdf_path, output_dir, lower_crop_extra=200):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    pdf = fitz.open(pdf_path)\n",
    "    print(f\"[INFO] Loaded '{pdf_path}' with {len(pdf)} pages.\")\n",
    "\n",
    "    for i, page in enumerate(pdf, start=1):\n",
    "        pix = page.get_pixmap(dpi=200)\n",
    "        img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
    "\n",
    "        # Crop lower for slides 1–2\n",
    "        if i in [1, 2]:\n",
    "            w, h = img.size\n",
    "            crop_box = (0, 0, w, min(h + lower_crop_extra, h))\n",
    "            img = img.crop(crop_box)\n",
    "\n",
    "        img.save(os.path.join(output_dir, f\"slide_{i:02d}.png\"), \"PNG\")\n",
    "\n",
    "    print(f\"Extracted {len(pdf)} slides from {pdf_path}\")\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "def ocr_folder(folder, label):\n",
    "    docs = []\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if fname.endswith(\".png\"):\n",
    "            path = os.path.join(folder, fname)\n",
    "            text = pytesseract.image_to_string(Image.open(path))\n",
    "            if text.strip():\n",
    "                docs.append(Document(\n",
    "                    page_content=text,\n",
    "                    metadata={\"image_path\": path, \"source_report\": label}\n",
    "                ))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract slides and OCR\n",
    "pdf_path = []\n",
    "for folder in [\"presentations\"]:\n",
    "    files = glob.glob(f\"{DATA_DIR}/{folder}/*.pdf\")\n",
    "    pdf_path.extend(files)\n",
    "\n",
    "print(f\"Processing {len(pdf_path)} PDFs from all folders\")\n",
    "\n",
    "docs = []\n",
    "for pdf in pdf_path:\n",
    "    # Create output folder based on PDF name\n",
    "    pdf_name = os.path.splitext(os.path.basename(pdf))[0]\n",
    "    slide_folder = f\"{DATA_DIR}/presentations/slides_{pdf_name}\"\n",
    "    \n",
    "    print(f\"Extracting slides from {pdf_name}...\")\n",
    "    extract_slides_fitz(pdf, slide_folder)\n",
    "    \n",
    "    # OCR the extracted slides\n",
    "    pdf_docs = ocr_folder(slide_folder, pdf_name)\n",
    "    docs.extend(pdf_docs)\n",
    "\n",
    "print(f\"Loaded {len(docs)} slide documents from {len(pdf_path)} PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1856ac0",
   "metadata": {},
   "source": [
    "### Chunk (BASELINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02db870",
   "metadata": {},
   "source": [
    "#### Text + Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file\n",
    "with open(f\"{DATA_DIR}/test.json\", \"r\") as f:\n",
    "    doc = json.load(f)\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for fileDoc , docContent in doc.items():\n",
    "    for page_num, content in docContent.items():\n",
    "        page_section = content.get(\"page_section\", \"unknown\")\n",
    "        text = content.get(\"text\", \"\")\n",
    "        tables = content.get(\"tables\", [])\n",
    "\n",
    "        if text.strip():\n",
    "            chunks.append({\n",
    "                \"id\": f\"{fileDoc}-page-{page_num}-text\",\n",
    "                \"text\": f\"Financial filing text section: {text}\",\n",
    "                \"metadata\": {\"document\": fileDoc, \"page_number\": page_num, \"page_section\": page_section, \"chunk_type\": \"prose\"}\n",
    "            })\n",
    "\n",
    "        if tables:\n",
    "            for t_index, table in enumerate(tables):\n",
    "                    table_text = \"\\n\".join([\", \".join(row) for row in table.get(\"rows\", [])])\n",
    "                    table_markdown = table.get(\"markdown\", \"\")\n",
    "\n",
    "                    chunks.append({\n",
    "                        \"id\": f\"{fileDoc}-page-{page_num}-table-{t_index}\",\n",
    "                        \"text\": f\"Financial statement table: {table_text}\",\n",
    "                        \"markdown\": table_markdown,\n",
    "                        \"metadata\": {\n",
    "                            \"document\": fileDoc,\n",
    "                            \"page_number\": page_num,\n",
    "                            \"page_section\": page_section,\n",
    "                            \"chunk_type\": \"table\",\n",
    "                            \"table_index\": t_index\n",
    "                            }\n",
    "                    })\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa25419",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [ chunk[\"text\"] for chunk in chunks ]\n",
    "\n",
    "embeddings = embed_text_passage (text)\n",
    "\n",
    "print (f\"Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "# Create a FAISS index - IP for normalized embeddings\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "print (f\"FAISS index contains {index.ntotal} vectors.\")\n",
    "\n",
    "# save it locally\n",
    "output_dir = f\"{DATA_DIR}/base\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# storing the index\n",
    "faiss.write_index(index, f\"{output_dir}/base.faiss\")\n",
    "print(f\"Index saved to {output_dir}/base.faiss\")\n",
    "\n",
    "# store the chunks\n",
    "with open(f\"{DATA_DIR}/base/chunks.json\", \"w\") as f:\n",
    "    json.dump(chunks, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b70a4",
   "metadata": {},
   "source": [
    "#### Slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54d41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract slides and OCR (already extracted, just need to OCR)\n",
    "docs_q1 = ocr_folder(f\"slides_q1_2025\", \"Q1_2025\")\n",
    "docs_q2 = ocr_folder(f\"slides_q2_2025\", \"Q2_2025\")\n",
    "docs = docs_q1 + docs_q2\n",
    "print(f\"Loaded {len(docs)} slide documents.\")\n",
    "\n",
    "slide_chunks = []\n",
    "for doc in docs:\n",
    "    # Extract slide number from filename (e.g., \"slide_01.png\" -> 1)\n",
    "    filename = os.path.basename(doc.metadata['image_path'])\n",
    "    slide_num = int(filename.split('_')[1].split('.')[0])\n",
    "    \n",
    "    slide_chunks.append({\n",
    "        \"id\": f\"{doc.metadata['source_report']}-slide-{slide_num:02d}\",\n",
    "        \"text\": doc.page_content,\n",
    "        \"metadata\": {\n",
    "            \"source_report\": doc.metadata['source_report'],\n",
    "            \"image_path\": doc.metadata['image_path'],\n",
    "            \"slide_number\": slide_num,\n",
    "            \"chunk_type\": \"slide\"\n",
    "        }\n",
    "    })\n",
    "\n",
    "print(f\"Created {len(slide_chunks)} slide chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f93afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_texts = [doc.page_content for doc in docs]\n",
    "\n",
    "slide_embeddings = embed_text_passage (slide_texts)\n",
    "\n",
    "print (f\"Slide Embeddings shape: {slide_embeddings.shape}\")\n",
    "\n",
    "# Create a FAISS index - IP for normalized embeddings\n",
    "slide_index = faiss.IndexFlatIP(slide_embeddings.shape[1])\n",
    "slide_index.add(slide_embeddings)\n",
    "print (f\"FAISS index contains {slide_index.ntotal} vectors.\")\n",
    "\n",
    "# save it locally\n",
    "output_dir = f\"{DATA_DIR}/base\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# storing the index\n",
    "faiss.write_index(slide_index, f\"{output_dir}/slides.faiss\")\n",
    "print(f\"Index saved to {output_dir}/slides.faiss\")\n",
    "\n",
    "with open(f\"{output_dir}/chunks_slides.json\", \"w\") as f:\n",
    "    json.dump(slide_chunks, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d72ec50",
   "metadata": {},
   "source": [
    "### Retrieval STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6accb453",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {}\n",
    "\n",
    "def init_indexes():\n",
    "    global index\n",
    "\n",
    "    # Load base index\n",
    "    documents_base_dir = f\"{DATA_DIR}/base/base.faiss\"\n",
    "    index[\"index\"] = faiss.read_index(documents_base_dir)\n",
    "    index[\"chunks\"] = json.load(open(f\"{DATA_DIR}/base/chunks.json\"))\n",
    "\n",
    "    # Load slides index\n",
    "    documents_slides_dir = f\"{DATA_DIR}/base/slides.faiss\"\n",
    "    index[\"slides_index\"] = faiss.read_index(documents_slides_dir)\n",
    "    index[\"chunks_slides\"] = json.load(open(f\"{DATA_DIR}/base/chunks_slides.json\"))\n",
    "\n",
    "    print (f\"chunks type : {type(index['chunks'])}, length: {len(index['chunks'])}\")\n",
    "    print (f\"chunks_slides type : {type(index['chunks_slides'])}, length: {len(index['chunks_slides'])}\")\n",
    "\n",
    "def search_query(query, k=10):\n",
    "    global index\n",
    "    query_embedding = embed_text_query(query)  # Convert query to vector\n",
    "\n",
    "    D, I = index[\"index\"].search(np.array([query_embedding]), k=k)\n",
    "    # D = distances/scores\n",
    "    # I = indices of top k matching chunks\n",
    "\n",
    "    results = [\n",
    "        {\n",
    "            \"rank\": rank + 1,\n",
    "            \"score\": float(D[0][rank]),\n",
    "            \"text\": index[\"chunks\"][identified_chunk_idx][\"text\"],\n",
    "            \"markdown\": index[\"chunks\"][identified_chunk_idx].get(\"markdown\", \"\"),\n",
    "            \"metadata\": index[\"chunks\"][identified_chunk_idx][\"metadata\"]\n",
    "        }\n",
    "        for rank, identified_chunk_idx in enumerate(I[0])\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_slides_query(query, k=3):\n",
    "    global index\n",
    "    query_embedding = embed_text_query(query)  # Convert query to vector\n",
    "\n",
    "    D, I = index[\"slides_index\"].search(np.array([query_embedding]), k=k)\n",
    "    # D = distances/scores\n",
    "    # I = indices of top k matching chunks\n",
    "\n",
    "    results = [\n",
    "        {\n",
    "            \"rank\": rank + 1,\n",
    "            \"score\": float(D[0][rank]),\n",
    "            \"text\": index[\"chunks_slides\"][identified_chunk_idx][\"text\"],\n",
    "            \"metadata\": index[\"chunks_slides\"][identified_chunk_idx][\"metadata\"]\n",
    "        }\n",
    "        for rank, identified_chunk_idx in enumerate(I[0])\n",
    "    ]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de798ce",
   "metadata": {},
   "source": [
    "#### Output print helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075cc8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import shorten\n",
    "from tabulate import tabulate\n",
    "\n",
    "def pretty_print_results(results, show_table=False):\n",
    "    table_data = []\n",
    "    for r in results:\n",
    "        meta = r[\"metadata\"]\n",
    "        chunk_type = meta.get(\"chunk_type\", \"unknown\")\n",
    "        section = meta.get(\"page_section\", \"unknown\")\n",
    "        doc = meta.get(\"document\", \"unknown\")\n",
    "        page = meta.get(\"page_number\", \"?\")\n",
    "        score = f\"{r['score']:.3f}\"\n",
    "        \n",
    "        # shorten text for preview\n",
    "        preview = shorten(r['text'], width=120, placeholder=\"…\")\n",
    "        table_data.append([r['rank'], score, chunk_type, section, doc, page, preview])\n",
    "\n",
    "    headers = [\"Rank\", \"Score\", \"Type\", \"Section\", \"Document\", \"Page\", \"Preview\"]\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"github\"))\n",
    "\n",
    "    # print markdown tables\n",
    "    if show_table:\n",
    "        for r in results:\n",
    "            if r[\"metadata\"][\"chunk_type\"] == \"table\" and r.get(\"markdown\"):\n",
    "                print(f\"\\n Table from {r['metadata']['document']} (p.{r['metadata']['page_number']}):\\n\")\n",
    "                print(r[\"markdown\"])\n",
    "                print(\"\\n\" + \"-\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize once\n",
    "init_indexes()\n",
    "\n",
    "# Search\n",
    "results = search_query(\"Q1 2024 revenue\", k=5)\n",
    "\n",
    "# print(results)\n",
    "pretty_print_results(results, show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec705cd",
   "metadata": {},
   "source": [
    "#### Slides Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5c4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "query = \"2025 Q1 revenue\"\n",
    "results = search_slides_query(query, k=3)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"\\n--- Result {r['rank']} ---\")\n",
    "    print(f\"Score: {r['score']:.4f}\")\n",
    "    print(\"Caption:\", r[\"text\"])\n",
    "    \n",
    "    image_path = r[\"metadata\"].get(\"image_path\")\n",
    "    if image_path and os.path.exists(image_path):\n",
    "        display(Image(filename=image_path, width=600))\n",
    "    else:\n",
    "        print(\"(Image not found)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd1b418",
   "metadata": {},
   "source": [
    "## 4. Baseline Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377249d1",
   "metadata": {},
   "source": [
    "### Agent Config and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.schema import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a97a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0) # consider 4o (will be a lot better but bye bye johnathan's credits)\n",
    "\n",
    "\n",
    "# guiding prompt\n",
    "system_prompt = \"\"\"\n",
    "You are a financial analyst assistant that can use tools.\n",
    "\n",
    "When given retrieved data:\n",
    "1. Identify all relevant components (e.g., for Operating Expenses: R&D, Sales & Marketing, G&A)\n",
    "2. Extract the values for the requested years\n",
    "3. Calculate using standard financial formulas\n",
    "4. Cite each component source\n",
    "\n",
    "If data is incomplete, state what's missing.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a282a",
   "metadata": {},
   "source": [
    "### Context Formatter (logs the context also) (BASELINE VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context(query, results, use_markdown=False, base : bool = True, expanded_query: str = \"\") -> str :\n",
    "    \"\"\"\n",
    "    Format retrieval results (from documents or slides) into a readable text context.\n",
    "    Automatically detects the source type from metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    # save it locally \n",
    "    dir = f\"{DATA_DIR}/logs/base\" if base else f\"{DATA_DIR}/logs/sections/\" \n",
    "    file_name = generate_test_log_path_name(f\"{dir}\") \n",
    "\n",
    "\n",
    "    # add the query then save the results as json \n",
    "    with open(file_name, \"w\") as f: \n",
    "        json.dump({\n",
    "            \"query\": query, \n",
    "            \"expanded_query\": expanded_query, \n",
    "            \"results\": results \n",
    "        }, f, indent=4)  \n",
    "        \n",
    "    parts = []\n",
    "    for r in results:\n",
    "        meta = r[\"metadata\"]\n",
    "        text = r.get(\"markdown\") if use_markdown and r.get(\"markdown\") else r[\"text\"].strip()\n",
    "\n",
    "        # Detect the type of source (document vs slide)\n",
    "        if \"document\" in meta:\n",
    "            doc = meta.get(\"document\", \"unknown\")\n",
    "            page = meta.get(\"page_number\", \"?\")\n",
    "            section = meta.get(\"page_section\", \"\")\n",
    "            header = f\"[{doc}, page {page}] {section}\".strip()\n",
    "        elif \"source_report\" in meta:\n",
    "            src = meta.get(\"source_report\", \"unknown report\")\n",
    "            slide = meta.get(\"slide_number\", \"?\")\n",
    "            header = f\"[{src}, Slide {slide}]\"\n",
    "        else:\n",
    "            header = \"[unknown source]\"\n",
    "\n",
    "        parts.append(f\"{header}\\n{text}\")\n",
    "\n",
    "    return \"\\n\\n---\\n\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17871fc7",
   "metadata": {},
   "source": [
    "## Table Search Function - To be replaced (Joc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e681aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tables_only(query: str, k: int = 5) -> str:\n",
    "    \"\"\"Retrieve ONLY tables for structured financial data\"\"\"\n",
    "    search_k = k * 2\n",
    "    \n",
    "    query_embedding = embed_text_query(query)\n",
    "    D, I = index[\"index\"].search(np.array([query_embedding]), k=search_k)\n",
    "\n",
    "    # Filter to keep ONLY tables\n",
    "    table_results = []\n",
    "    for rank, idx in enumerate(I[0]):\n",
    "        if idx < len(index[\"chunks\"]):\n",
    "            chunk = index[\"chunks\"][idx]\n",
    "            if chunk['metadata'].get('chunk_type') == 'table':\n",
    "                table_results.append({\n",
    "                    'rank': rank + 1,\n",
    "                    'score': float(D[0][rank]),\n",
    "                    'text': chunk['text'],\n",
    "                    'markdown': chunk.get('markdown', ''),\n",
    "                    'metadata': chunk['metadata']\n",
    "                })\n",
    "                if len(table_results) >= k:\n",
    "                    break\n",
    "    \n",
    "    return table_results \n",
    "\n",
    "def search_all_chunks(query: str) -> str:\n",
    "    \"\"\"Smart retrieval based on query type\"\"\"\n",
    "\n",
    "    financial_terms = ['revenue', 'expense', 'income', 'margin', 'ratio', 'opex', \n",
    "                          'cost', 'profit', 'loss', 'cash flow']\n",
    "    is_financial = any(term in query.lower() for term in financial_terms)\n",
    "\n",
    "    #!!!!!!\n",
    "    #!========================================================================================\n",
    "                        #!REMOVING THE FINANCIAL PART FOR NOW TO TEST#!\n",
    "    #!========================================================================================\n",
    "    # if is_financial:\n",
    "    #     print (\"Detected financial query, retrieving tables only.\") \n",
    "    #     # Dynamic k based on query complexity\n",
    "    #     k = 10 if any(word in query.lower() for word in \n",
    "    #                  [\"operating expense\", \"opex\", \"trend\", \"breakdown\"]) else 5\n",
    "    #     results = search_tables_only(query, k=k)\n",
    "    \n",
    "    # else: \n",
    "    #!======================================================================================== \n",
    "    #! ======================================================================================= \n",
    "    #!!!!!! \n",
    "    print (\"Detected non-financial query, retrieving all chunks.\")\n",
    "    # Retrieve from both sources\n",
    "    doc_results = search_query(query)\n",
    "    slide_results = search_slides_query(query)\n",
    "\n",
    "    results = doc_results + slide_results \n",
    "    print (f\"Combining {len(doc_results)} doc results and {len(slide_results)} slide results.\") \n",
    "    print (\"=\"*60)\n",
    "    print (f\"combined Results : {results} \")\n",
    "    print (\"=\"*60)\n",
    "    \n",
    "    return format_context(query, results, use_markdown=True)         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8739c295",
   "metadata": {},
   "source": [
    "#### Retriever Tool (BASELINE VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec6ce48",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;129m@tool\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretriever\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_direct\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretriever_tool\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"  \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Use this tool to look up information in finance documents, spreadsheets, or reports.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    It retrieves the most relevant text or table snippets related to the given question.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    Especially helpful for questions like \"total operating expenses\" or \"revenue growth by year\".\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     results \u001b[38;5;241m=\u001b[39m search_query(query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tool' is not defined"
     ]
    }
   ],
   "source": [
    "@tool(\"retriever\", return_direct=False)\n",
    "def retriever_tool(query: str) -> str:\n",
    "    \"\"\"  \n",
    "    Use this tool to look up information in finance documents, spreadsheets, or reports.\n",
    "    It retrieves the most relevant text or table snippets related to the given question.\n",
    "    Especially helpful for questions like \"total operating expenses\" or \"revenue growth by year\".\n",
    "    \"\"\"\n",
    "    results = search_query(query, k=5)\n",
    "    return format_context(query, results, use_markdown=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abe040d",
   "metadata": {},
   "source": [
    "#### Calculator Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20357143",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"calculator\", return_direct=False)\n",
    "def calculator_tool(expression: str) -> str:\n",
    "    \"\"\"Safely evaluate a mathematical expression, e.g. (165 - 150) / 150 * 100.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292fb45f",
   "metadata": {},
   "source": [
    "#### Agent -> ONE LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751aaeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Rule-based Agent\n",
    "def rule_based_agent(query: str):\n",
    "    \"\"\"Simple rule-based routing - no LLM for tool selection\"\"\"\n",
    "    \n",
    "    # Rule 1: If query mentions calculation keywords -> retrieve + calculate\n",
    "    calc_keywords = ['ratio', 'percentage', 'growth', 'change', 'calculate', 'compute']\n",
    "    needs_calc = any(word in query.lower() for word in calc_keywords)\n",
    "    \n",
    "    retrieval_result = search_all_chunks(query)\n",
    "\n",
    "    # Rule 3: If calculation needed, extract numbers and compute\n",
    "    if needs_calc:\n",
    "        # Simple extraction logic (you can enhance this)\n",
    "        numbers = re.findall(r'\\d+\\.?\\d*', retrieval_result)\n",
    "\n",
    "    return retrieval_result\n",
    "\n",
    "# Baseline pipeline\n",
    "query = \"Show Total Operating Expenses for 2022, 2023 and 2024.\"\n",
    "\n",
    "query =  [\"Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\",\n",
    "          \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\",\n",
    "          \"Calculate the Operating Efficiency Ratio (Opex ÷ Operating Income) for the last 3 fiscal years, showing the working.\"]\n",
    "\n",
    "query = query[0] \n",
    "# 1. Rule-based retrieval (no LLM)\n",
    "retrieval_result = rule_based_agent(query)\n",
    "\n",
    "\n",
    "# 2. ONE LLM call for final answer generation\n",
    "final_response = llm.invoke([\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=f\"Query: {query}\\n\\nRetrieved Data:\\n{retrieval_result}\\n\\nProvide final answer with citations in the required JSON format.\")\n",
    "])\n",
    "\n",
    "# Results\n",
    "print(\"=== Final Answer ===\")\n",
    "print(final_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ff0afc",
   "metadata": {},
   "source": [
    "#### Agent -> multiple LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, calculator_tool]\n",
    "\n",
    "#ReAct agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc129f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit runtime + iterations\n",
    "#!!! can be skipped since initialize_agent has alr returned a AgentExecutor \n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent.agent,\n",
    "    tools=tools,\n",
    "    max_iterations=3,\n",
    "    max_execution_time=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615afa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Show Total Operating Expenses for 2022, 2023 and 2024.\"\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"input\": [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=query)\n",
    "    ]\n",
    "})\n",
    "print(response[\"output\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb4824",
   "metadata": {},
   "source": [
    "## 5. Benchmark Runner\n",
    "\n",
    "Run these 3 standardized queries. Produce JSON then prose answers with citations. These are the standardized queries.\n",
    "\n",
    "*   Gross Margin Trend (or NIM if Bank)\n",
    "    *   Query: \"Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\"\n",
    "    *   Expected Output: A quarterly table of Gross Margin % (or NIM % if bank).\n",
    "\n",
    "*   Operating Expenses (Opex) YoY for 3 Years\n",
    "    *   Query: \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
    "    *   Expected Output: A 3-year Opex table (absolute numbers and % change).\n",
    "\n",
    "*   Operating Efficiency Ratio\n",
    "    *   Query: \"Calculate the Operating Efficiency Ratio (Opex ÷ Operating Income) for the last 3 fiscal years, showing the working.\"\n",
    "    *   Expected Output: Table with Opex, Operating Income, and calculated ratio for 3 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement benchmark runner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a08304",
   "metadata": {},
   "source": [
    "## 6. Instrumentation\n",
    "\n",
    "Log timings: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total. Log tokens, cache hits, tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example instrumentation schema\n",
    "import pandas as pd\n",
    "logs = pd.DataFrame(columns=['Query','T_ingest','T_retrieve','T_rerank','T_reason','T_generate','T_total','Tokens','CacheHits','Tools'])\n",
    "logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9633ca2e",
   "metadata": {},
   "source": [
    "## 7. Optimizations\n",
    "\n",
    "**Required Optimizations**\n",
    "\n",
    "Each team must implement at least:\n",
    "*   2 retrieval optimizations (e.g., hybrid BM25+vector, smaller embeddings, dynamic k).\n",
    "*   1 caching optimization (query cache or ratio cache).\n",
    "*   1 agentic optimization (plan pruning, parallel sub-queries).\n",
    "*   1 system optimization (async I/O, batch embedding, memory-mapped vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da131ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement optimizations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93269f7f",
   "metadata": {},
   "source": [
    "### EMBEDDINGS (USING OPENAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f5c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# choose your model\n",
    "EMBED_MODEL = \"text-embedding-3-small\"  # or \"text-embedding-3-large\"\n",
    "\n",
    "def embed_text_query(s):\n",
    "    # E5 expects a prefix; same here for consistency\n",
    "    text = f\"query: {s.strip().lower()}\"\n",
    "    response = client.embeddings.create(model=EMBED_MODEL, input=text)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def embed_text_passage(chunks):\n",
    "    # Normalize and add E5-like prefix to all passages\n",
    "    inputs = [f\"passage: {chunk.strip().lower()}\" for chunk in chunks]\n",
    "    response = client.embeddings.create(model=EMBED_MODEL, input=inputs)\n",
    "    # convert it to numpy array\n",
    "    embeddings = np.array([d.embedding for d in response.data])\n",
    "    # return a list of numpy-like vectors\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a54a2e",
   "metadata": {},
   "source": [
    "### CHUNKING (SECTION INDEXES) (OPTIMIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "#*  Classify Chunks (Section/Hierachical Chunking)\n",
    "\n",
    " # turn each section into a faiss index\n",
    "indexes = {} \n",
    "sections = defaultdict(list) \n",
    "\n",
    "# --- Group chunks by section ---\n",
    "for c in chunks: \n",
    "    section = c[\"metadata\"].get(\"page_section\", \"unknown\") \n",
    "    sections[section].append(c) \n",
    "\n",
    "sections_path = f\"{DATA_DIR}/sections\" \n",
    "\n",
    "\n",
    "# build per section index \n",
    "count = 0 \n",
    "for section , chunk_list in sections.items(): \n",
    "    print(f\"Building index for section: {section} ({len(chunk_list)} chunks)\")\n",
    "    text = [ chunk[\"text\"] for chunk in chunk_list ] \n",
    "    embeddings = embed_text_passage (text) \n",
    "\n",
    "    \n",
    "    print (f\"Embeddings shape for section {section}: {np.array(embeddings).shape}\") \n",
    "    idx = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "    idx.add(embeddings)\n",
    "\n",
    "\n",
    "    #os.makedirs(f\"Google/sections/{section}\", exist_ok=True)\n",
    "    # \n",
    "    os.makedirs(f\"{sections_path}/{section}\", exist_ok=True )\n",
    "      \n",
    "    # storing the index \n",
    "    faiss.write_index(idx, f\"{sections_path}/{section}/faiss_index_{section}.index\")\n",
    "\n",
    "    # storing the chunks \n",
    "    with open(f\"{sections_path}/{section}/chunks_{section}.json\", \"w\") as f:\n",
    "        json.dump(chunk_list, f, indent=4)\n",
    "\n",
    "    # storing the embeddings \n",
    "    np.save(f\"{sections_path}/{section}/embeddings_{section}.npy\", embeddings) \n",
    "    count += 1\n",
    "    \n",
    "print(f\"✅ Built {count} FAISS sub-indexes.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e6886",
   "metadata": {},
   "source": [
    "## INIT INDEXES (SECTIONS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86c4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = {} \n",
    "\n",
    "\n",
    "def init_indexes(): \n",
    "    \"\"\"this dont need run if its in the same session\"\"\"\n",
    "\n",
    "    \n",
    "    documents_base_dir = f\"{DATA_DIR}/sections\" \n",
    "    sections_path = [os.path.join(documents_base_dir, f) for f in os.listdir(documents_base_dir) if os.path.isdir(os.path.join(documents_base_dir, f)) ]\n",
    "    print (\"Sections found:\", sections_path) \n",
    "\n",
    "    for sec_path in sections_path: \n",
    "        section = os.path.basename(sec_path) \n",
    "        #print (f\"Loading section: {section}\") \n",
    "\n",
    "        # load faiss \n",
    "        idx = faiss.read_index(f\"{sec_path}/faiss_index_{section}.index\") \n",
    "        indexes[section] = {\n",
    "            \"index\": idx,\n",
    "            \"chunks\": json.load(open(f\"{sec_path}/chunks_{section}.json\")) \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_indexes() \n",
    "\n",
    "print (f\"✅ Loaded {len(indexes)} section FAISS indexes.\") \n",
    "\n",
    "print (f\" Chunk text preview : {indexes['income_statement']['chunks'][0]['text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd6dc4e",
   "metadata": {},
   "source": [
    "### FORMATTING CONTEXT FOR SECTIONS INDEXES SEARCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context(query, results, use_markdown=False, base : bool = True, expanded_query: str = \"\") -> str :\n",
    "    \"\"\"\n",
    "    Format retrieval results (from documents or slides) into a readable text context.\n",
    "    Automatically detects the source type from metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    # save it locally \n",
    "    dir = f\"{DATA_DIR}/logs/base\" if base else f\"{DATA_DIR}/logs/sections/\" \n",
    "    file_name = generate_test_log_path_name(f\"{dir}\") \n",
    "\n",
    "\n",
    "    # add the query then save the results as json \n",
    "    with open(file_name, \"w\") as f: \n",
    "        json.dump({\n",
    "            \"query\": query, \n",
    "            \"expanded_query\": expanded_query, \n",
    "            \"results\": results \n",
    "        }, f, indent=4)  \n",
    "        \n",
    "    parts = []\n",
    "    for section_data in results:\n",
    "        section = section_data.get(\"section\", \"unknown\") \n",
    "        parts.append(f\"## Section: {section}\\n\") \n",
    "        for r in section_data.get(\"ranking\", []):\n",
    "            meta = r[\"metadata\"]\n",
    "            text = r.get(\"markdown\") if use_markdown and r.get(\"markdown\") else r[\"text\"].strip()\n",
    "\n",
    "            # Detect the type of source (document vs slide)\n",
    "            if \"document\" in meta:\n",
    "                doc = meta.get(\"document\", \"unknown\")\n",
    "                page = meta.get(\"page_number\", \"?\")\n",
    "                section = meta.get(\"page_section\", \"\")\n",
    "                header = f\"[{doc}, page {page}] {section}\".strip()\n",
    "            elif \"source_report\" in meta:\n",
    "                src = meta.get(\"source_report\", \"unknown report\")\n",
    "                slide = meta.get(\"slide_number\", \"?\")\n",
    "                header = f\"[{src}, Slide {slide}]\"\n",
    "            else:\n",
    "                header = \"[unknown source]\"\n",
    "\n",
    "            parts.append(f\"{header}\\n{text} \")\n",
    "\n",
    "    return \"\\n\\n---\\n\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5af121",
   "metadata": {},
   "source": [
    "### Search Query (Sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45338dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(expanded_query, sections : list ,k=10):\n",
    "\n",
    "    \"\"\"\n",
    "    Search across section-specific FAISS indexes for a given (already expanded) query.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"[INFO] Searching {len(sections)} sections for: '{expanded_query}'\")\n",
    "\n",
    "    query_embedding = embed_text_query(expanded_query) \n",
    "    #D_all, I_all = [], [] \n",
    "    results = []\n",
    "\n",
    "\n",
    "    for sec in sections: \n",
    "        if sec in indexes: \n",
    "            idx = indexes[sec][\"index\"]\n",
    "            D, I = idx.search(np.array([query_embedding]), k=min(k, idx.ntotal))\n",
    "            # D_all.append(D)\n",
    "            # I_all.append(I)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"section\": sec, \n",
    "                    \"ranking\" : [\n",
    "                        {\n",
    "                            \"rank\": rank + 1 , \n",
    "                            \"score\": float(D[0][rank]), \n",
    "                            \"text\": indexes[sec][\"chunks\"][identified_chunk_idx][\"text\"], \n",
    "                            \"metadata\": indexes[sec][\"chunks\"][identified_chunk_idx][\"metadata\"] \n",
    "                        }   for rank, identified_chunk_idx in enumerate(I[0])           \n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            print(f\"[WARN] Section '{sec}' not found in indexes.\") \n",
    "\n",
    "    print (f\"[INFO] Completed search across sections.\")\n",
    "    print (f\"results preview : {results[:1]} ... \")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0a1ea6",
   "metadata": {},
   "source": [
    "### Internal Helper (EXPAND QUERY + choose sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea2fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def choose_sections_for_query(query: str, available_sections: list) -> list:\n",
    "    \"\"\"Internal helper — not a tool.\"\"\"\n",
    "    sec_list = \", \".join(available_sections)\n",
    "    prompt = f\"\"\"\n",
    "    You are a financial data retrieval router.\n",
    "    Given the user's question and the available 10-Q sections, \n",
    "    select the most relevant section(s) to search for an answer.\n",
    "\n",
    "    Available sections: {sec_list}\n",
    "    User question: {query}\n",
    "\n",
    "    Return a JSON array of section names from the list above. Strictly start with '[' and end with ']'.\n",
    "    Example output: [\"income_statement\", \"balance_sheet\"]\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([SystemMessage(content=prompt)])\n",
    "\n",
    "    try:\n",
    "        selected = json.loads(response.content)\n",
    "        if isinstance(selected, list):\n",
    "            return [sec for sec in selected if sec in available_sections]\n",
    "        return []\n",
    "    except Exception:\n",
    "        return []\n",
    "    \n",
    "def expand_query_for_retrieval(query: str) -> str:\n",
    "    \"\"\"Internal helper — not a tool.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Expand the following financial query to improve retrieval from SEC filings.\n",
    "\n",
    "    Guidelines:\n",
    "    - Include synonyms (e.g., \"operating expenses\" → \"SG&A\", \"total expenses\").\n",
    "    - Include both annual and quarterly phrasing (e.g., “fiscal year”, “quarter ended”).\n",
    "    - Include context like \"Consolidated Statements of Income\", \"Statements of Operations\".\n",
    "    - Keep it short but keyword-dense (2–3 sentences).\n",
    "\n",
    "    User query: \"{query}\"\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content.strip()\n",
    "\n",
    "\n",
    "def safe_json_loads(s):\n",
    "    \"\"\"Tries to parse JSON even if it has weird hidden chars or minor formatting issues.\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            cleaned = (\n",
    "                s.strip(\"` \\n\\t'\\\"\")          # remove outer quotes / markdown ticks / newlines\n",
    "                .replace(\"'\", '\"')            # replace single quotes with double\n",
    "                .replace(\"\\ufeff\", \"\")        # remove BOM marker\n",
    "            )\n",
    "            # remove trailing commas or stray markdown\n",
    "            cleaned = re.sub(r\",\\s*}\", \"}\", cleaned)\n",
    "            cleaned = re.sub(r\",\\s*]\", \"]\", cleaned)\n",
    "            return json.loads(cleaned)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] safe_json_loads still failed: {e}\")\n",
    "            print(f\"[DEBUG] Cleaned candidate: {repr(cleaned)}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfd8c52",
   "metadata": {},
   "source": [
    "### RETRIEVER TOOL (internally choose sections and expand queries if llm agent didnt provide the sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd47c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool(\"retriever\", return_direct=False)\n",
    "def retriever_tool(query : str ) -> str: \n",
    "    \"\"\"\n",
    "    Retrieve relevant text snippets from financial filings.\n",
    "\n",
    "    Accepts:\n",
    "    - A plain query string (e.g., \"Show total operating expenses for 2023\").\n",
    "    - Or a JSON string with fields:\n",
    "        query: financial question\n",
    "        sections: list of section names such as [\"income_statement\", \"balance_sheet\"]\n",
    "\n",
    "    If no sections are provided, the tool will automatically choose the most relevant ones.\n",
    "    \"\"\"\n",
    "\n",
    "    available_sections = list(indexes.keys())\n",
    "\n",
    "    print (f\"[RETRIEVER_TOOL] agent provided query: {query}\")\n",
    "    print (f\"[RETRIEVER_TOOL] query type: {type(query)}\") \n",
    "    \n",
    "\n",
    "    parsed = safe_json_loads(query)\n",
    "\n",
    "    # 1️⃣ Try to parse JSON input if agent passes structured info\n",
    "    if parsed:\n",
    "        print(f\"[INFO] Parsed agent input: {parsed}\")\n",
    "        query = parsed.get(\"query\", query)\n",
    "        sections = parsed.get(\"sections\", None)\n",
    "        print(f\"[INFO] Agent provided query: {query}\")\n",
    "        print(f\"[INFO] Agent provided sections: {sections}\")\n",
    "    else:\n",
    "        print(\"[INFO] No structured sections provided, will auto-select.\")\n",
    "        sections = None\n",
    "\n",
    "    # 1️⃣ Expand query internally\n",
    "    expanded_query = expand_query_for_retrieval(query)\n",
    "\n",
    "    # 2️⃣ If agent didn't pass sections, auto-select\n",
    "    if not sections:\n",
    "        sections = choose_sections_for_query(expanded_query, available_sections)\n",
    "        print (f\"[INFO] Auto selected sections: {sections}\") \n",
    "        if not sections:\n",
    "            sections = available_sections  # fallback to all sections \n",
    "\n",
    "    # 3️⃣ Perform retrieval\n",
    "    results = search_query(expanded_query, sections, k=5) \n",
    "    return format_context(query, results, use_markdown=True, base=False, expanded_query=expanded_query) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f9d1f",
   "metadata": {},
   "source": [
    "## Available Sections Retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"available_sections_retriever\", return_direct=False) \n",
    "def available_sections_retriever(query: str = \"\") -> list:\n",
    "    \"\"\"\n",
    "    List all available sections in the indexed financial filings.\n",
    "\n",
    "    Returns a JSON array of section names, e.g.:\n",
    "    [\"income_statement\", \"balance_sheet\", \"cash_flow\", \"mdna\", \"risk_factors\"].\n",
    "\n",
    "    Useful for understanding which sections can be queried via the retriever tool.\n",
    "    \"\"\"\n",
    "\n",
    "    return list(indexes.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "# 1️⃣ init indexes\n",
    "init_indexes()\n",
    "\n",
    "# 2️⃣ model\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# 3️⃣ system message\n",
    "system_prompt = \"\"\"\n",
    "You are a financial analyst assistant that can use tools.\n",
    "\n",
    "When given retrieved data:\n",
    "1. Identify all relevant components (e.g., for Operating Expenses: R&D, Sales & Marketing, G&A)\n",
    "2. Extract the values for the requested years\n",
    "3. Calculate using standard financial formulas\n",
    "4. Cite each component source\n",
    "\n",
    "If data is incomplete, state what's missing.\n",
    "\"\"\"\n",
    "\n",
    "# 4️⃣ tools\n",
    "tools = [retriever_tool, calculator_tool, available_sections_retriever]\n",
    "\n",
    "# 5️⃣ initialize agent (already returns an AgentExecutor)\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True,\n",
    "    agent_kwargs={\"system_message\": SystemMessage(content=system_prompt)}\n",
    ")\n",
    "\n",
    "agent.max_iterations = None \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5229a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Show Total Operating Expenses for 2022, 2023 and 2024.\"\n",
    "query =  [\"Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\",\n",
    "          \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\",\n",
    "          \"Calculate the Operating Efficiency Ratio (Opex ÷ Operating Income) for the last 3 fiscal years, showing the working.\"]\n",
    "\n",
    "query = query[2] \n",
    "\n",
    "response = agent.invoke({\n",
    "    \"input\": query,\n",
    "    '\"query\"': query   # notice the quotes *inside* the string key\n",
    "})\n",
    "\n",
    "\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3668af8",
   "metadata": {},
   "source": [
    "## 8. Results & Plots\n",
    "\n",
    "Show baseline vs optimized. Include latency plots (p50/p95) and accuracy tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate plots with matplotlib\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
