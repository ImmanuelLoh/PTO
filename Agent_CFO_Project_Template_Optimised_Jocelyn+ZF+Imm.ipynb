{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb673291",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pdfplumber\n",
        "!pip install camelot-py[cv]\n",
        "!pip install --upgrade pymupdf\n",
        "!pip install google-generativeai\n",
        "!pip install faiss-cpu\n",
        "!pip install transformers tqdm pandas pytesseract pillow easyocr langchain langchain-community langchain_openai faiss-cpu rank_bm25 pdf2image\n",
        "!pip install sentence_transformers\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc348c92",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import re\n",
        "import os, glob\n",
        "import pdfplumber\n",
        "import camelot\n",
        "import pymupdf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import time\n",
        "import faiss, json\n",
        "import collections\n",
        "import fitz\n",
        "import io\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from langchain_core.documents import Document\n",
        "from openai import OpenAI\n",
        "from TableRetrieval.table_ingestion import stage1_extract_and_save\n",
        "from TableRetrieval.table_ingestion import store_in_faiss, save_metadata_mapping\n",
        "from TableRetrieval.table_agentic_rag import TableAgenticRAG\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb8e4733",
      "metadata": {
        "id": "bb8e4733"
      },
      "source": [
        "# Agent CFO — Performance Optimization & Design\n",
        "\n",
        "---\n",
        "This is the starter notebook for your project. Follow the required structure below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wkMIj4Ssetku",
      "metadata": {
        "id": "wkMIj4Ssetku"
      },
      "source": [
        "You will design and optimize an Agent CFO assistant for a listed company. The assistant should answer finance/operations questions using RAG (Retrieval-Augmented Generation) + agentic reasoning, with response time (latency) as the primary metric.\n",
        "\n",
        "Your system must:\n",
        "*   Ingest the company’s public filings.\n",
        "*   Retrieve relevant passages efficiently.\n",
        "*   Compute ratios/trends via tool calls (calculator, table parsing).\n",
        "*   Produce answers with valid citations to the correct page/table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c138dd7",
      "metadata": {
        "id": "0c138dd7"
      },
      "source": [
        "## 1. Config & Secrets\n",
        "\n",
        "Fill in your API keys in secrets. **Do not hardcode keys** in cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a6098a4",
      "metadata": {
        "id": "8a6098a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Example:\n",
        "# os.environ['GEMINI_API_KEY'] = 'your-key-here'\n",
        "# os.environ['OPENAI_API_KEY'] = 'your-key-here'\n",
        "\n",
        "COMPANY_NAME = \"Google\"\n",
        "\n",
        "CHUNK_SIZE = 500  # number of words per chunk \n",
        "\n",
        "def generate_test_log_path_name(base_path: str): \n",
        "    # create the directory if not exist \n",
        "    os.makedirs(base_path, exist_ok=True) \n",
        "    existing_files = [f for f in os.listdir(base_path) if f.startswith(\"test_\") and f.endswith(\".json\")] \n",
        "    existing_indices = [int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()] \n",
        "    next_index = max(existing_indices) + 1 if existing_indices else 1 \n",
        "\n",
        "    return f\"{base_path}/test_{next_index}.json\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b7a81e9",
      "metadata": {
        "id": "8b7a81e9"
      },
      "source": [
        "## 2. Data Download (Dropbox)\n",
        "\n",
        "*   Annual Reports: last 3–5 years.\n",
        "*   Quarterly Results Packs & MD&A (Management Discussion & Analysis).\n",
        "*   Investor Presentations and Press Releases.\n",
        "*   These files must be submitted later as a deliverable in the Dropbox data pack.\n",
        "*   Upload them under `/content/data/`.\n",
        "\n",
        "Scope limit: each team will ingest minimally 15 PDF files total.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b2e844",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = \"00-data\"\n",
        "\n",
        "# Annual reports (10-Ks)\n",
        "annual_files = glob.glob(f\"{DATA_DIR}/annuals/*.pdf\")\n",
        "\n",
        "# # Quarterly reports (10-Qs)\n",
        "quarterly_files = glob.glob(f\"{DATA_DIR}/quarterlies/*.pdf\")\n",
        "\n",
        "# Presentations\n",
        "presentation_files = glob.glob(f\"{DATA_DIR}/presentations/*.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cb44836",
      "metadata": {},
      "outputs": [],
      "source": [
        "for folder in [\"annuals\", \"quarterlies\", \"presentations\"]:\n",
        "\n",
        "    files = glob.glob(f\"{DATA_DIR}/{folder}/*.pdf\")\n",
        "    print(f\"{folder}: {len(files)} files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d4e754",
      "metadata": {
        "id": "b0d4e754"
      },
      "source": [
        "## 3. System Requirements\n",
        "\n",
        "**Retrieval & RAG**\n",
        "*   Use a vector index (e.g., FAISS, LlamaIndex) + a keyword filter (BM25/ElasticSearch).\n",
        "*   Citations must include: report name, year, page number, section/table.\n",
        "\n",
        "**Agentic Reasoning**\n",
        "*   Support at least 3 tool types: calculator, table extraction, multi-document compare.\n",
        "*   Reasoning must follow a plan-then-act pattern (not a single unstructured call).\n",
        "\n",
        "**Instrumentation**\n",
        "*   Log timings for: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total.\n",
        "*   Log: tokens used, cache hits, tools invoked.\n",
        "*   Record p50/p95 latencies."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e7db324",
      "metadata": {},
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07ca36ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_embeddings(chunks, model=\"text-embedding-3-small\"):\n",
        "    \"\"\"\n",
        "    Create embeddings for chunks using OpenAI.\n",
        "    Returns: chunks with 'embedding' field added\n",
        "    \"\"\"\n",
        "    print(f\"Creating embeddings with {model}...\\n\")\n",
        "    print(f\"   Total chunks: {len(chunks)}\")\n",
        "    \n",
        "    client = OpenAI()\n",
        "\n",
        "    # Split into batches of 50\n",
        "    batch_size = 50\n",
        "    total_batches = (len(chunks) + batch_size - 1) // batch_size\n",
        "\n",
        "    for i in range(0, len(chunks), batch_size):\n",
        "        batch = chunks[i:i + batch_size]\n",
        "        batch_num = i // batch_size + 1\n",
        "        print(f\"   Processing batch {batch_num} of {total_batches}...\")\n",
        "\n",
        "        contents = [chunk['content'] for chunk in batch]\n",
        "        \n",
        "        # Embed batch\n",
        "        response = client.embeddings.create(\n",
        "            model=model,\n",
        "            input=contents\n",
        "        )\n",
        "        \n",
        "        # Add embeddings to chunks\n",
        "        for j, chunk in enumerate(batch):\n",
        "            chunk['embedding'] = response.data[j].embedding\n",
        "\n",
        "        # Small delay to respect rate limits\n",
        "        if i + batch_size < len(chunks):\n",
        "                time.sleep(0.6) # Adjust as needed\n",
        "    \n",
        "    print(f\"Created {len(chunks)} embeddings\\n\")\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "771f03d6",
      "metadata": {},
      "source": [
        "### Table Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ed7484",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stage2_create_embeddings(json_file):\n",
        "    \"\"\"\n",
        "    Load extracted tables from JSON and create embeddings.\n",
        "    This is where you spend OpenAI tokens.\n",
        "    \"\"\"\n",
        "    load_dotenv()\n",
        "    \n",
        "    DATA_DIR = \"00-data\"\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "    print(\"STAGE 2: CREATING EMBEDDINGS\")\n",
        "    print(\"=\"*80)\n",
        "    print()\n",
        "    \n",
        "    # Load the extracted tables\n",
        "    print(f\"Loading: {json_file}\")\n",
        "    with open(json_file, 'r') as f:\n",
        "        table_chunks = json.load(f)\n",
        "    \n",
        "    print(f\"Loaded {len(table_chunks)} tables\")\n",
        "    \n",
        "    print(\"\\nCreating embeddings...\")\n",
        "    embedded_chunks = create_embeddings(table_chunks)\n",
        "    \n",
        "    print(\"\\nStoring in FAISS...\")\n",
        "    faiss_index = store_in_faiss(\n",
        "        embedded_chunks,\n",
        "        faiss_index_path=f\"{DATA_DIR}/base/faiss_table_index\"\n",
        "    )\n",
        "    \n",
        "    print(\"\\nSaving metadata...\")\n",
        "    save_metadata_mapping(\n",
        "        embedded_chunks,\n",
        "        mapping_path=f\"{DATA_DIR}/base/faiss_table_metadata.json\"\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"COMPLETE!\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"FAISS index: {DATA_DIR}/base/faiss_table_index\")\n",
        "    print(f\"Metadata: {DATA_DIR}/base/faiss_table_metadata.json\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03435447",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert table ingestion code here\n",
        "stage1_extract_and_save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad03ce98",
      "metadata": {},
      "outputs": [],
      "source": [
        "stage2_create_embeddings(f\"{DATA_DIR}/extracted_tables.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48c69c03",
      "metadata": {},
      "source": [
        "### Slides Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab5b53ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "from ImageRetrieval.ImageRetrieval import ImageRetriever\n",
        "from ImageRetrieval.slides_extractor import extract_slides_fitz\n",
        "from ImageRetrieval.ocr_extractor import ocr_folder\n",
        "from ImageRetrieval.image_faiss_builder import (\n",
        "    create_image_embeddings,\n",
        "    store_image_faiss,\n",
        "    save_image_metadata\n",
        ")\n",
        "\n",
        "IMAGE_INDEX_PATH = \"00-data/base/faiss_image_index\"\n",
        "IMAGE_META_PATH  = \"00-data/base/faiss_image_metadata.json\"\n",
        "\n",
        "slide_docs = []\n",
        "\n",
        "pdf_files = glob.glob(\"00-data/presentations/*.pdf\")\n",
        "print(f\"[ImagePipeline] Found {len(pdf_files)} presentation PDFs.\")\n",
        "\n",
        "for pdf in pdf_files:\n",
        "    pdf_name = os.path.splitext(os.path.basename(pdf))[0]\n",
        "    out_dir = f\"00-data/presentations/slides_{pdf_name}\"\n",
        "\n",
        "    extract_slides_fitz(pdf, out_dir)\n",
        "    slide_docs.extend(ocr_folder(out_dir, label=pdf_name))\n",
        "\n",
        "print(f\"[ImagePipeline] Total OCR slide documents: {len(slide_docs)}\")\n",
        "\n",
        "# Embed\n",
        "embeddings = create_image_embeddings(slide_docs)\n",
        "\n",
        "# FAISS + metadata\n",
        "store_image_faiss(embeddings, IMAGE_INDEX_PATH)\n",
        "save_image_metadata(slide_docs, IMAGE_META_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be601cd6",
      "metadata": {},
      "source": [
        "### Text Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddeeabc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from TextRetrieval.TextExtractor import extract_text_from_pdf\n",
        "extract_text_from_pdf(); \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edc6bf96",
      "metadata": {},
      "source": [
        "## TEXT FAISS BUILDER\n",
        "### CREATE THE CHUNKS \n",
        "### BUILD THE INDICES BASE OFF THE CHUNKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d27882f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from TextRetrieval.TextFaissBuilder import create_chunks, built_indices\n",
        "\n",
        "chunks = create_chunks();\n",
        "built_indices(chunks); "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ffb05fc",
      "metadata": {
        "id": "6ffb05fc"
      },
      "source": [
        "## 4. Baseline Pipeline\n",
        "\n",
        "**Baseline (starting point)**\n",
        "*   Naive chunking.\n",
        "*   Single-pass vector search.\n",
        "*   One LLM call, no caching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540b7020",
      "metadata": {
        "id": "540b7020"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement baseline retrieval + generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e9e3ea",
      "metadata": {
        "id": "01e9e3ea"
      },
      "source": [
        "## 5. Benchmark Runner\n",
        "\n",
        "Run these 3 standardized queries. Produce JSON then prose answers with citations. These are the standardized queries.\n",
        "\n",
        "*   Gross Margin Trend (or NIM if Bank)\n",
        "    *   Query: \"Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\"\n",
        "    *   Expected Output: A quarterly table of Gross Margin % (or NIM % if bank).\n",
        "\n",
        "*   Operating Expenses (Opex) YoY for 3 Years\n",
        "    *   Query: \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
        "    *   Expected Output: A 3-year Opex table (absolute numbers and % change).\n",
        "\n",
        "*   Operating Efficiency Ratio\n",
        "    *   Query: \"Calculate the Operating Efficiency Ratio (Opex ÷ Operating Income) for the last 3 fiscal years, showing the working.\"\n",
        "    *   Expected Output: Table with Opex, Operating Income, and calculated ratio for 3 years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7bddc40",
      "metadata": {
        "id": "e7bddc40"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement benchmark runner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683ebeda",
      "metadata": {
        "id": "683ebeda"
      },
      "source": [
        "## 6. Instrumentation\n",
        "\n",
        "Log timings: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total. Log tokens, cache hits, tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5425de5",
      "metadata": {
        "id": "d5425de5"
      },
      "outputs": [],
      "source": [
        "# Example instrumentation schema\n",
        "import pandas as pd\n",
        "logs = pd.DataFrame(columns=['Query','T_ingest','T_retrieve','T_rerank','T_reason','T_generate','T_total','Tokens','CacheHits','Tools'])\n",
        "logs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c01bf4",
      "metadata": {
        "id": "e8c01bf4"
      },
      "source": [
        "## 7. Optimizations\n",
        "\n",
        "**Required Optimizations**\n",
        "\n",
        "Each team must implement at least:\n",
        "*   2 retrieval optimizations (e.g., hybrid BM25+vector, smaller embeddings, dynamic k).\n",
        "*   1 caching optimization (query cache or ratio cache).\n",
        "*   1 agentic optimization (plan pruning, parallel sub-queries).\n",
        "*   1 system optimization (async I/O, batch embedding, memory-mapped vectors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783f0e2e",
      "metadata": {
        "id": "783f0e2e"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement optimizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5894d19a",
      "metadata": {},
      "source": [
        "### Table Agentic Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e126e8d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "FAISS_INDEX = f\"{DATA_DIR}/base/faiss_table_index\"\n",
        "METADATA_JSON = f\"{DATA_DIR}/base/faiss_table_metadata.json\"\n",
        "\n",
        "# Create the agent\n",
        "table_agent = TableAgenticRAG(\n",
        "    faiss_index_path=FAISS_INDEX,\n",
        "    metadata_json_path=METADATA_JSON\n",
        ")\n",
        "\n",
        "query = \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
        "\n",
        "\n",
        "print(\"\\nRunning agent query...\\n\")\n",
        "result = table_agent.query(query, verbose=True)\n",
        "\n",
        "\n",
        "print(\"\\n====================== ANSWER ======================\")\n",
        "print(result[\"answer\"])\n",
        "print(\"===================================================\\n\")\n",
        "\n",
        "\n",
        "print(\"Sources:\", result[\"sources\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b9f1f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "query2 = \"What is the operating expense for the last 3 fiscal years, year-on-year comparison.\"\n",
        "print(\"\\nRunning agent query 2...\\n\")\n",
        "result = table_agent.query(query2, verbose=True)\n",
        "\n",
        "print(\"\\n====================== ANSWER ======================\")\n",
        "print(result[\"answer\"])\n",
        "print(\"===================================================\\n\")\n",
        "\n",
        "\n",
        "print(\"Sources:\", result[\"sources\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c2a9b93",
      "metadata": {},
      "source": [
        "### TEXT Agentic Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84787646",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from TextRetrieval.Agent import text_agent_executor\n",
        "\n",
        "# query = \"\" \\\n",
        "# \"What is the operating expense for the last 3 fiscal years, year-on-year comparison.\"\n",
        "# text_agent_executor(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a169e9b",
      "metadata": {},
      "source": [
        "### Image Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "255e2285",
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "IMAGE_INDEX = \"00-data/base/faiss_image_index\"\n",
        "IMAGE_META  = \"00-data/base/faiss_image_metadata.json\"\n",
        "\n",
        "image_retriever = ImageRetriever(IMAGE_INDEX, IMAGE_META)\n",
        "query = \"What are the operating expenses?\"\n",
        "results = image_retriever.search(query, k=5)\n",
        "results\n",
        "path = results[0][\"metadata\"][\"image_path\"]\n",
        "Image.open(path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74d90f09",
      "metadata": {},
      "source": [
        "## Unified Agent Query Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42ad8208",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from UnifiedCFOAgent import create_cfo_agent\n",
        "\n",
        "# agent = create_cfo_agent()\n",
        "\n",
        "# query = \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
        "\n",
        "# # response = agent.invoke({\"input\": query})\n",
        "\n",
        "# response = agent.invoke({\"input\": query}, return_intermediate_steps=True)\n",
        "\n",
        "# print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cdc13b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from UnifiedCFOAgent import query_cfo_agent\n",
        "question = \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
        "response = query_cfo_agent(\n",
        "    question,\n",
        "    cache_threshold=0.85,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "print(response[\"answer\"])\n",
        "print(response[\"metadata\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "676536c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"What is the operating expense for the last 3 fiscal years, year-on-year comparison.\"\n",
        "response = query_cfo_agent(\n",
        "    question,\n",
        "    cache_threshold=0.85,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "print(response[\"answer\"])\n",
        "print(response[\"metadata\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "155414af",
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"Calculate the Operating Efficiency Ratio (Opex ÷ Operating Income) for the last 3 fiscal years, showing the working.\"\n",
        "response = query_cfo_agent(\n",
        "    question,\n",
        "    cache_threshold=0.85,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a36e1b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"What are the operating expenses?\"\n",
        "response = query_cfo_agent(\n",
        "    question,\n",
        "    cache_threshold=0.85,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c68a1a62",
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"Where can i get a graphic representation of the operating expenses?\"\n",
        "response = query_cfo_agent(\n",
        "    question,\n",
        "    cache_threshold=0.85,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a91ce833",
      "metadata": {
        "id": "a91ce833"
      },
      "source": [
        "## 8. Results & Plots\n",
        "\n",
        "Show baseline vs optimized. Include latency plots (p50/p95) and accuracy tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96550f3",
      "metadata": {
        "id": "d96550f3"
      },
      "outputs": [],
      "source": [
        "# TODO: Generate plots with matplotlib\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
