{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb673291",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pdfplumber\n",
        "!pip install camelot-py[cv]\n",
        "!pip install --upgrade pymupdf\n",
        "!pip install google-generativeai\n",
        "!pip install faiss-cpu\n",
        "!pip install transformers tqdm pandas pytesseract pillow easyocr langchain langchain-community langchain_openai faiss-cpu rank_bm25 pdf2image\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc348c92",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import re\n",
        "import os, glob\n",
        "import pdfplumber\n",
        "import camelot\n",
        "import pymupdf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import time\n",
        "import faiss, json\n",
        "import collections\n",
        "import fitz\n",
        "import io\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from langchain_core.documents import Document\n",
        "from openai import OpenAI\n",
        "from TableRetrieval.table_ingestion import stage1_extract_and_save\n",
        "from TableRetrieval.table_ingestion import store_in_faiss, save_metadata_mapping\n",
        "from TableRetrieval.table_agentic_rag import TableAgenticRAG\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb8e4733",
      "metadata": {
        "id": "bb8e4733"
      },
      "source": [
        "# Agent CFO — Performance Optimization & Design\n",
        "\n",
        "---\n",
        "This is the starter notebook for your project. Follow the required structure below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wkMIj4Ssetku",
      "metadata": {
        "id": "wkMIj4Ssetku"
      },
      "source": [
        "You will design and optimize an Agent CFO assistant for a listed company. The assistant should answer finance/operations questions using RAG (Retrieval-Augmented Generation) + agentic reasoning, with response time (latency) as the primary metric.\n",
        "\n",
        "Your system must:\n",
        "*   Ingest the company’s public filings.\n",
        "*   Retrieve relevant passages efficiently.\n",
        "*   Compute ratios/trends via tool calls (calculator, table parsing).\n",
        "*   Produce answers with valid citations to the correct page/table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c138dd7",
      "metadata": {
        "id": "0c138dd7"
      },
      "source": [
        "## 1. Config & Secrets\n",
        "\n",
        "Fill in your API keys in secrets. **Do not hardcode keys** in cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a6098a4",
      "metadata": {
        "id": "8a6098a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Example:\n",
        "# os.environ['GEMINI_API_KEY'] = 'your-key-here'\n",
        "# os.environ['OPENAI_API_KEY'] = 'your-key-here'\n",
        "\n",
        "COMPANY_NAME = \"Google\"\n",
        "\n",
        "CHUNK_SIZE = 500  # number of words per chunk \n",
        "\n",
        "def generate_test_log_path_name(base_path: str): \n",
        "    # create the directory if not exist \n",
        "    os.makedirs(base_path, exist_ok=True) \n",
        "    existing_files = [f for f in os.listdir(base_path) if f.startswith(\"test_\") and f.endswith(\".json\")] \n",
        "    existing_indices = [int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()] \n",
        "    next_index = max(existing_indices) + 1 if existing_indices else 1 \n",
        "\n",
        "    return f\"{base_path}/test_{next_index}.json\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b7a81e9",
      "metadata": {
        "id": "8b7a81e9"
      },
      "source": [
        "## 2. Data Download (Dropbox)\n",
        "\n",
        "*   Annual Reports: last 3–5 years.\n",
        "*   Quarterly Results Packs & MD&A (Management Discussion & Analysis).\n",
        "*   Investor Presentations and Press Releases.\n",
        "*   These files must be submitted later as a deliverable in the Dropbox data pack.\n",
        "*   Upload them under `/content/data/`.\n",
        "\n",
        "Scope limit: each team will ingest minimally 15 PDF files total.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b2e844",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = \"00-data\"\n",
        "\n",
        "# Annual reports (10-Ks)\n",
        "annual_files = glob.glob(f\"{DATA_DIR}/annuals/*.pdf\")\n",
        "\n",
        "# # Quarterly reports (10-Qs)\n",
        "quarterly_files = glob.glob(f\"{DATA_DIR}/quarterlies/*.pdf\")\n",
        "\n",
        "# Presentations\n",
        "presentation_files = glob.glob(f\"{DATA_DIR}/presentations/*.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cb44836",
      "metadata": {},
      "outputs": [],
      "source": [
        "for folder in [\"annuals\", \"quarterlies\", \"presentations\"]:\n",
        "\n",
        "    files = glob.glob(f\"{DATA_DIR}/{folder}/*.pdf\")\n",
        "    print(f\"{folder}: {len(files)} files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d4e754",
      "metadata": {
        "id": "b0d4e754"
      },
      "source": [
        "## 3. System Requirements\n",
        "\n",
        "**Retrieval & RAG**\n",
        "*   Use a vector index (e.g., FAISS, LlamaIndex) + a keyword filter (BM25/ElasticSearch).\n",
        "*   Citations must include: report name, year, page number, section/table.\n",
        "\n",
        "**Agentic Reasoning**\n",
        "*   Support at least 3 tool types: calculator, table extraction, multi-document compare.\n",
        "*   Reasoning must follow a plan-then-act pattern (not a single unstructured call).\n",
        "\n",
        "**Instrumentation**\n",
        "*   Log timings for: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total.\n",
        "*   Log: tokens used, cache hits, tools invoked.\n",
        "*   Record p50/p95 latencies."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e7db324",
      "metadata": {},
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07ca36ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_embeddings(chunks, model=\"text-embedding-3-small\"):\n",
        "    \"\"\"\n",
        "    Create embeddings for chunks using OpenAI.\n",
        "    Returns: chunks with 'embedding' field added\n",
        "    \"\"\"\n",
        "    print(f\"Creating embeddings with {model}...\\n\")\n",
        "    print(f\"   Total chunks: {len(chunks)}\")\n",
        "    \n",
        "    client = OpenAI()\n",
        "\n",
        "    # Split into batches of 50\n",
        "    batch_size = 50\n",
        "    total_batches = (len(chunks) + batch_size - 1) // batch_size\n",
        "\n",
        "    for i in range(0, len(chunks), batch_size):\n",
        "        batch = chunks[i:i + batch_size]\n",
        "        batch_num = i // batch_size + 1\n",
        "        print(f\"   Processing batch {batch_num} of {total_batches}...\")\n",
        "\n",
        "        contents = [chunk['content'] for chunk in batch]\n",
        "        \n",
        "        # Embed batch\n",
        "        response = client.embeddings.create(\n",
        "            model=model,\n",
        "            input=contents\n",
        "        )\n",
        "        \n",
        "        # Add embeddings to chunks\n",
        "        for j, chunk in enumerate(batch):\n",
        "            chunk['embedding'] = response.data[j].embedding\n",
        "\n",
        "        # Small delay to respect rate limits\n",
        "        if i + batch_size < len(chunks):\n",
        "                time.sleep(0.6) # Adjust as needed\n",
        "    \n",
        "    print(f\"Created {len(chunks)} embeddings\\n\")\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "771f03d6",
      "metadata": {},
      "source": [
        "### Table Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ed7484",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stage2_create_embeddings(json_file):\n",
        "    \"\"\"\n",
        "    Load extracted tables from JSON and create embeddings.\n",
        "    This is where you spend OpenAI tokens.\n",
        "    \"\"\"\n",
        "    load_dotenv()\n",
        "    \n",
        "    DATA_DIR = \"00-data\"\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "    print(\"STAGE 2: CREATING EMBEDDINGS\")\n",
        "    print(\"=\"*80)\n",
        "    print()\n",
        "    \n",
        "    # Load the extracted tables\n",
        "    print(f\"Loading: {json_file}\")\n",
        "    with open(json_file, 'r') as f:\n",
        "        table_chunks = json.load(f)\n",
        "    \n",
        "    print(f\"Loaded {len(table_chunks)} tables\")\n",
        "    \n",
        "    print(\"\\nCreating embeddings...\")\n",
        "    embedded_chunks = create_embeddings(table_chunks)\n",
        "    \n",
        "    print(\"\\nStoring in FAISS...\")\n",
        "    faiss_index = store_in_faiss(\n",
        "        embedded_chunks,\n",
        "        faiss_index_path=f\"{DATA_DIR}/base/faiss_table_index\"\n",
        "    )\n",
        "    \n",
        "    print(\"\\nSaving metadata...\")\n",
        "    save_metadata_mapping(\n",
        "        embedded_chunks,\n",
        "        mapping_path=f\"{DATA_DIR}/base/faiss_table_metadata.json\"\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"COMPLETE!\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"FAISS index: {DATA_DIR}/base/faiss_table_index\")\n",
        "    print(f\"Metadata: {DATA_DIR}/base/faiss_table_metadata.json\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03435447",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert table ingestion code here\n",
        "stage1_extract_and_save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad03ce98",
      "metadata": {},
      "outputs": [],
      "source": [
        "stage2_create_embeddings(f\"{DATA_DIR}/extracted_tables.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be601cd6",
      "metadata": {},
      "source": [
        "## Text Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddeeabc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from TextRetrieval.TextExtractor import extract_text_from_pdf\n",
        "\n",
        "extract_text_from_pdf(); "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48c69c03",
      "metadata": {},
      "source": [
        "### Slides Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab5b53ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_slides_fitz(pdf_path, output_dir, lower_crop_extra=200):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    pdf = fitz.open(pdf_path)\n",
        "    print(f\"[INFO] Loaded '{pdf_path}' with {len(pdf)} pages.\")\n",
        "\n",
        "    for i, page in enumerate(pdf, start=1):\n",
        "        pix = page.get_pixmap(dpi=200)\n",
        "        img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
        "\n",
        "        # Crop lower for slides 1–2\n",
        "        if i in [1, 2]:\n",
        "            w, h = img.size\n",
        "            crop_box = (0, 0, w, min(h + lower_crop_extra, h))\n",
        "            img = img.crop(crop_box)\n",
        "\n",
        "        img.save(os.path.join(output_dir, f\"slide_{i:02d}.png\"), \"PNG\")\n",
        "\n",
        "    print(f\"Extracted {len(pdf)} slides from {pdf_path}\")\n",
        "\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "def ocr_folder(folder, label):\n",
        "    docs = []\n",
        "    for fname in sorted(os.listdir(folder)):\n",
        "        if fname.endswith(\".png\"):\n",
        "            path = os.path.join(folder, fname)\n",
        "            text = pytesseract.image_to_string(Image.open(path))\n",
        "            if text.strip():\n",
        "                docs.append(Document(\n",
        "                    page_content=text,\n",
        "                    metadata={\"image_path\": path, \"source_report\": label}\n",
        "                ))\n",
        "    return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1ec3457",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract slides and OCR\n",
        "pdf_path = []\n",
        "for folder in [\"presentations\"]:\n",
        "    files = glob.glob(f\"{DATA_DIR}/{folder}/*.pdf\")\n",
        "    pdf_path.extend(files)\n",
        "\n",
        "print(f\"Processing {len(pdf_path)} PDFs from all folders\")\n",
        "\n",
        "docs = []\n",
        "for pdf in pdf_path:\n",
        "    # Create output folder based on PDF name\n",
        "    pdf_name = os.path.splitext(os.path.basename(pdf))[0]\n",
        "    slide_folder = f\"{DATA_DIR}/presentations/slides_{pdf_name}\"\n",
        "    \n",
        "    print(f\"Extracting slides from {pdf_name}...\")\n",
        "    extract_slides_fitz(pdf, slide_folder)\n",
        "    \n",
        "    # OCR the extracted slides\n",
        "    pdf_docs = ocr_folder(slide_folder, pdf_name)\n",
        "    docs.extend(pdf_docs)\n",
        "\n",
        "print(f\"Loaded {len(docs)} slide documents from {len(pdf_path)} PDFs.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edc6bf96",
      "metadata": {},
      "source": [
        "## TEXT FAISS BUILDER\n",
        "### CREATE THE CHUNKS \n",
        "### BUILD THE INDICES BASE OFF THE CHUNKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d27882f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from TextRetrieval.TextFaissBuilder import create_chunks, built_indices\n",
        "\n",
        "chunks = create_chunks();\n",
        "built_indices(chunks); "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ffb05fc",
      "metadata": {
        "id": "6ffb05fc"
      },
      "source": [
        "## 4. Baseline Pipeline\n",
        "\n",
        "**Baseline (starting point)**\n",
        "*   Naive chunking.\n",
        "*   Single-pass vector search.\n",
        "*   One LLM call, no caching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540b7020",
      "metadata": {
        "id": "540b7020"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement baseline retrieval + generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e9e3ea",
      "metadata": {
        "id": "01e9e3ea"
      },
      "source": [
        "## 5. Benchmark Runner\n",
        "\n",
        "Run these 3 standardized queries. Produce JSON then prose answers with citations. These are the standardized queries.\n",
        "\n",
        "*   Gross Margin Trend (or NIM if Bank)\n",
        "    *   Query: \"Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\"\n",
        "    *   Expected Output: A quarterly table of Gross Margin % (or NIM % if bank).\n",
        "\n",
        "*   Operating Expenses (Opex) YoY for 3 Years\n",
        "    *   Query: \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
        "    *   Expected Output: A 3-year Opex table (absolute numbers and % change).\n",
        "\n",
        "*   Operating Efficiency Ratio\n",
        "    *   Query: \"Calculate the Operating Efficiency Ratio (Opex ÷ Operating Income) for the last 3 fiscal years, showing the working.\"\n",
        "    *   Expected Output: Table with Opex, Operating Income, and calculated ratio for 3 years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7bddc40",
      "metadata": {
        "id": "e7bddc40"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement benchmark runner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683ebeda",
      "metadata": {
        "id": "683ebeda"
      },
      "source": [
        "## 6. Instrumentation\n",
        "\n",
        "Log timings: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total. Log tokens, cache hits, tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5425de5",
      "metadata": {
        "id": "d5425de5"
      },
      "outputs": [],
      "source": [
        "# Example instrumentation schema\n",
        "import pandas as pd\n",
        "logs = pd.DataFrame(columns=['Query','T_ingest','T_retrieve','T_rerank','T_reason','T_generate','T_total','Tokens','CacheHits','Tools'])\n",
        "logs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c01bf4",
      "metadata": {
        "id": "e8c01bf4"
      },
      "source": [
        "## 7. Optimizations\n",
        "\n",
        "**Required Optimizations**\n",
        "\n",
        "Each team must implement at least:\n",
        "*   2 retrieval optimizations (e.g., hybrid BM25+vector, smaller embeddings, dynamic k).\n",
        "*   1 caching optimization (query cache or ratio cache).\n",
        "*   1 agentic optimization (plan pruning, parallel sub-queries).\n",
        "*   1 system optimization (async I/O, batch embedding, memory-mapped vectors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783f0e2e",
      "metadata": {
        "id": "783f0e2e"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement optimizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5894d19a",
      "metadata": {},
      "source": [
        "### Table Agentic Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e126e8d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "FAISS_INDEX = f\"{DATA_DIR}/base/faiss_table_index\"\n",
        "METADATA_JSON = f\"{DATA_DIR}/base/faiss_table_metadata.json\"\n",
        "\n",
        "# Create the agent\n",
        "table_agent = TableAgenticRAG(\n",
        "    faiss_index_path=FAISS_INDEX,\n",
        "    metadata_json_path=METADATA_JSON\n",
        ")\n",
        "\n",
        "query = \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
        "\n",
        "\n",
        "print(\"\\nRunning agent query...\\n\")\n",
        "result = table_agent.query(query, verbose=True)\n",
        "\n",
        "\n",
        "print(\"\\n====================== ANSWER ======================\")\n",
        "print(result[\"answer\"])\n",
        "print(\"===================================================\\n\")\n",
        "\n",
        "\n",
        "print(\"Sources:\", result[\"sources\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b9f1f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "query2 = \"What is the operating expense for the last 3 fiscal years, year-on-year comparison.\"\n",
        "print(\"\\nRunning agent query 2...\\n\")\n",
        "result = table_agent.query(query2, verbose=True)\n",
        "\n",
        "print(\"\\n====================== ANSWER ======================\")\n",
        "print(result[\"answer\"])\n",
        "print(\"===================================================\\n\")\n",
        "\n",
        "\n",
        "print(\"Sources:\", result[\"sources\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c2a9b93",
      "metadata": {},
      "source": [
        "### TEXT Agentic Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84787646",
      "metadata": {},
      "outputs": [],
      "source": [
        "from TextRetrieval.Agent import text_agent_executor\n",
        "\n",
        "query = \"\" \\\n",
        "\"What is the operating expense for the last 3 fiscal years, year-on-year comparison.\"\n",
        "text_agent_executor(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b13db19d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a91ce833",
      "metadata": {
        "id": "a91ce833"
      },
      "source": [
        "## 8. Results & Plots\n",
        "\n",
        "Show baseline vs optimized. Include latency plots (p50/p95) and accuracy tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96550f3",
      "metadata": {
        "id": "d96550f3"
      },
      "outputs": [],
      "source": [
        "# TODO: Generate plots with matplotlib\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
