{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bb673291",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pdfplumber in c:\\python312\\lib\\site-packages (0.11.7)\n",
            "Requirement already satisfied: pdfminer.six==20250506 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from pdfplumber) (20250506)\n",
            "Requirement already satisfied: Pillow>=9.1 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from pdfplumber) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\python312\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from pdfminer.six==20250506->pdfplumber) (46.0.1)\n",
            "Requirement already satisfied: cffi>=2.0.0 in c:\\python312\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in c:\\python312\\lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: camelot-py[cv] in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (1.0.9)\n",
            "Requirement already satisfied: click>=8.0.1 in c:\\python312\\lib\\site-packages (from camelot-py[cv]) (8.1.7)\n",
            "Requirement already satisfied: chardet>=5.1.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from camelot-py[cv]) (5.2.0)\n",
            "Requirement already satisfied: numpy>=1.26.1 in c:\\python312\\lib\\site-packages (from camelot-py[cv]) (1.26.4)\n",
            "Requirement already satisfied: openpyxl>=3.1.0 in c:\\python312\\lib\\site-packages (from camelot-py[cv]) (3.1.5)\n",
            "Requirement already satisfied: pdfminer-six>=20240706 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from camelot-py[cv]) (20250506)\n",
            "Requirement already satisfied: pypdf<6.0,>=4.0 in c:\\python312\\lib\\site-packages (from camelot-py[cv]) (5.9.0)\n",
            "Requirement already satisfied: pandas>=2.2.2 in c:\\python312\\lib\\site-packages (from camelot-py[cv]) (2.2.2)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in c:\\python312\\lib\\site-packages (from camelot-py[cv]) (0.9.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.7.0.68 in c:\\python312\\lib\\site-packages (from camelot-py[cv]) (4.11.0.86)\n",
            "Requirement already satisfied: pypdfium2>=4 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from camelot-py[cv]) (4.30.0)\n",
            "Requirement already satisfied: pillow>=10.4.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from camelot-py[cv]) (11.3.0)\n",
            "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from click>=8.0.1->camelot-py[cv]) (0.4.6)\n",
            "Requirement already satisfied: et-xmlfile in c:\\python312\\lib\\site-packages (from openpyxl>=3.1.0->camelot-py[cv]) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas>=2.2.2->camelot-py[cv]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas>=2.2.2->camelot-py[cv]) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas>=2.2.2->camelot-py[cv]) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\python312\\lib\\site-packages (from pdfminer-six>=20240706->camelot-py[cv]) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from pdfminer-six>=20240706->camelot-py[cv]) (46.0.1)\n",
            "Requirement already satisfied: cffi>=2.0.0 in c:\\python312\\lib\\site-packages (from cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py[cv]) (2.0.0)\n",
            "Requirement already satisfied: pycparser in c:\\python312\\lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py[cv]) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.2.2->camelot-py[cv]) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "WARNING: camelot-py 1.0.9 does not provide the extra 'cv'\n",
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymupdf in c:\\python312\\lib\\site-packages (1.26.5)\n",
            "Collecting pymupdf\n",
            "  Using cached pymupdf-1.26.6-cp310-abi3-win_amd64.whl.metadata (3.4 kB)\n",
            "Using cached pymupdf-1.26.6-cp310-abi3-win_amd64.whl (18.4 MB)\n",
            "Installing collected packages: pymupdf\n",
            "  Attempting uninstall: pymupdf\n",
            "    Found existing installation: PyMuPDF 1.26.5\n",
            "    Uninstalling PyMuPDF-1.26.5:\n",
            "      Successfully uninstalled PyMuPDF-1.26.5\n",
            "  Rolling back uninstall of PyMuPDF\n",
            "  Moving to c:\\python312\\lib\\site-packages\\fitz\\\n",
            "   from C:\\Python312\\Lib\\site-packages\\~itz\n",
            "  Moving to c:\\python312\\lib\\site-packages\\pymupdf-1.26.5.dist-info\\\n",
            "   from C:\\Python312\\Lib\\site-packages\\~ymupdf-1.26.5.dist-info\n",
            "  Moving to c:\\python312\\lib\\site-packages\\pymupdf\\\n",
            "   from C:\\Python312\\Lib\\site-packages\\~ymupdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
            "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python312\\\\Scripts\\\\pymupdf.exe' -> 'C:\\\\Python312\\\\Scripts\\\\pymupdf.exe.deleteme'\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-generativeai in c:\\python312\\lib\\site-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\python312\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in c:\\python312\\lib\\site-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in c:\\python312\\lib\\site-packages (from google-generativeai) (2.184.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in c:\\python312\\lib\\site-packages (from google-generativeai) (2.40.3)\n",
            "Requirement already satisfied: protobuf in c:\\python312\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.11.9)\n",
            "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (from google-generativeai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in c:\\python312\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\python312\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\python312\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\python312\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.6.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\python312\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\python312\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python312\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\python312\\lib\\site-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\python312\\lib\\site-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in c:\\python312\\lib\\site-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\python312\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in c:\\python312\\lib\\site-packages (from faiss-cpu) (24.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\python312\\lib\\site-packages (4.49.0)\n",
            "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (4.66.4)\n",
            "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: pytesseract in c:\\python312\\lib\\site-packages (0.3.13)\n",
            "Requirement already satisfied: pillow in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (11.3.0)\n",
            "Requirement already satisfied: easyocr in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (1.7.2)\n",
            "Requirement already satisfied: langchain in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-community in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (0.3.29)\n",
            "Requirement already satisfied: langchain_openai in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (0.3.33)\n",
            "Requirement already satisfied: faiss-cpu in c:\\python312\\lib\\site-packages (1.12.0)\n",
            "Requirement already satisfied: rank_bm25 in c:\\python312\\lib\\site-packages (0.2.2)\n",
            "Requirement already satisfied: pdf2image in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (1.17.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\python312\\lib\\site-packages (from transformers) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\python312\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\python312\\lib\\site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\python312\\lib\\site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: torch in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from easyocr) (2.4.0)\n",
            "Requirement already satisfied: torchvision>=0.5 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from easyocr) (0.19.0)\n",
            "Requirement already satisfied: opencv-python-headless in c:\\python312\\lib\\site-packages (from easyocr) (4.11.0.86)\n",
            "Requirement already satisfied: scipy in c:\\python312\\lib\\site-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: scikit-image in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from easyocr) (0.25.2)\n",
            "Requirement already satisfied: python-bidi in c:\\python312\\lib\\site-packages (from easyocr) (0.6.6)\n",
            "Requirement already satisfied: Shapely in c:\\python312\\lib\\site-packages (from easyocr) (2.0.4)\n",
            "Requirement already satisfied: pyclipper in c:\\python312\\lib\\site-packages (from easyocr) (1.3.0.post6)\n",
            "Requirement already satisfied: ninja in c:\\python312\\lib\\site-packages (from easyocr) (1.13.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (0.4.28)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.11.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\python312\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from langchain_openai) (1.107.3)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.4.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in c:\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in c:\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: sympy in c:\\python312\\lib\\site-packages (from torch->easyocr) (1.13.2)\n",
            "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch->easyocr) (75.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from scikit-image->easyocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in c:\\python312\\lib\\site-packages (from scikit-image->easyocr) (2025.10.4)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy->torch->easyocr) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence_transformers in c:\\python312\\lib\\site-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\python312\\lib\\site-packages (from sentence_transformers) (4.49.0)\n",
            "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from sentence_transformers) (2.4.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\python312\\lib\\site-packages (from sentence_transformers) (1.5.0)\n",
            "Requirement already satisfied: scipy in c:\\python312\\lib\\site-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\python312\\lib\\site-packages (from sentence_transformers) (0.29.1)\n",
            "Requirement already satisfied: Pillow in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from sentence_transformers) (11.3.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ngmin\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in c:\\python312\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.2)\n",
            "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (75.8.0)\n",
            "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\python312\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python312\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Python312\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber\n",
        "!pip install camelot-py[cv]\n",
        "!pip install --upgrade pymupdf\n",
        "!pip install google-generativeai\n",
        "!pip install faiss-cpu\n",
        "!pip install transformers tqdm pandas pytesseract pillow easyocr langchain langchain-community langchain_openai faiss-cpu rank_bm25 pdf2image\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fc348c92",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import re\n",
        "import os, glob\n",
        "import pdfplumber\n",
        "import camelot\n",
        "import pymupdf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import time\n",
        "import faiss, json\n",
        "import collections\n",
        "import fitz\n",
        "import io\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from langchain_core.documents import Document\n",
        "from openai import OpenAI\n",
        "from TableRetrieval.table_ingestion import stage1_extract_and_save\n",
        "from TableRetrieval.table_ingestion import store_in_faiss, save_metadata_mapping\n",
        "from TableRetrieval.table_agentic_rag import TableAgenticRAG\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb8e4733",
      "metadata": {
        "id": "bb8e4733"
      },
      "source": [
        "# Agent CFO — Performance Optimization & Design\n",
        "\n",
        "---\n",
        "This is the starter notebook for your project. Follow the required structure below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wkMIj4Ssetku",
      "metadata": {
        "id": "wkMIj4Ssetku"
      },
      "source": [
        "You will design and optimize an Agent CFO assistant for a listed company. The assistant should answer finance/operations questions using RAG (Retrieval-Augmented Generation) + agentic reasoning, with response time (latency) as the primary metric.\n",
        "\n",
        "Your system must:\n",
        "*   Ingest the company’s public filings.\n",
        "*   Retrieve relevant passages efficiently.\n",
        "*   Compute ratios/trends via tool calls (calculator, table parsing).\n",
        "*   Produce answers with valid citations to the correct page/table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c138dd7",
      "metadata": {
        "id": "0c138dd7"
      },
      "source": [
        "## 1. Config & Secrets\n",
        "\n",
        "Fill in your API keys in secrets. **Do not hardcode keys** in cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8a6098a4",
      "metadata": {
        "id": "8a6098a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Example:\n",
        "# os.environ['GEMINI_API_KEY'] = 'your-key-here'\n",
        "# os.environ['OPENAI_API_KEY'] = 'your-key-here'\n",
        "\n",
        "COMPANY_NAME = \"Google\"\n",
        "\n",
        "def generate_test_log_path_name(base_path: str): \n",
        "    # create the directory if not exist \n",
        "    os.makedirs(base_path, exist_ok=True) \n",
        "    existing_files = [f for f in os.listdir(base_path) if f.startswith(\"test_\") and f.endswith(\".json\")] \n",
        "    existing_indices = [int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()] \n",
        "    next_index = max(existing_indices) + 1 if existing_indices else 1 \n",
        "\n",
        "    return f\"{base_path}/test_{next_index}.json\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b7a81e9",
      "metadata": {
        "id": "8b7a81e9"
      },
      "source": [
        "## 2. Data Download (Dropbox)\n",
        "\n",
        "*   Annual Reports: last 3–5 years.\n",
        "*   Quarterly Results Packs & MD&A (Management Discussion & Analysis).\n",
        "*   Investor Presentations and Press Releases.\n",
        "*   These files must be submitted later as a deliverable in the Dropbox data pack.\n",
        "*   Upload them under `/content/data/`.\n",
        "\n",
        "Scope limit: each team will ingest minimally 15 PDF files total.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "80b2e844",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = \"00-data\"\n",
        "\n",
        "# Annual reports (10-Ks)\n",
        "annual_files = glob.glob(f\"{DATA_DIR}/annuals/*.pdf\")\n",
        "\n",
        "# # Quarterly reports (10-Qs)\n",
        "quarterly_files = glob.glob(f\"{DATA_DIR}/quarterlies/*.pdf\")\n",
        "\n",
        "# Presentations\n",
        "presentation_files = glob.glob(f\"{DATA_DIR}/presentations/*.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5cb44836",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "annuals: 3 files\n",
            "quarterlies: 11 files\n",
            "presentations: 2 files\n"
          ]
        }
      ],
      "source": [
        "for folder in [\"annuals\", \"quarterlies\", \"presentations\"]:\n",
        "\n",
        "    files = glob.glob(f\"{DATA_DIR}/{folder}/*.pdf\")\n",
        "    print(f\"{folder}: {len(files)} files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d4e754",
      "metadata": {
        "id": "b0d4e754"
      },
      "source": [
        "## 3. System Requirements\n",
        "\n",
        "**Retrieval & RAG**\n",
        "*   Use a vector index (e.g., FAISS, LlamaIndex) + a keyword filter (BM25/ElasticSearch).\n",
        "*   Citations must include: report name, year, page number, section/table.\n",
        "\n",
        "**Agentic Reasoning**\n",
        "*   Support at least 3 tool types: calculator, table extraction, multi-document compare.\n",
        "*   Reasoning must follow a plan-then-act pattern (not a single unstructured call).\n",
        "\n",
        "**Instrumentation**\n",
        "*   Log timings for: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total.\n",
        "*   Log: tokens used, cache hits, tools invoked.\n",
        "*   Record p50/p95 latencies."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e7db324",
      "metadata": {},
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07ca36ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_embeddings(chunks, model=\"text-embedding-3-small\"):\n",
        "    \"\"\"\n",
        "    Create embeddings for chunks using OpenAI.\n",
        "    Returns: chunks with 'embedding' field added\n",
        "    \"\"\"\n",
        "    print(f\"Creating embeddings with {model}...\\n\")\n",
        "    print(f\"   Total chunks: {len(chunks)}\")\n",
        "    \n",
        "    client = OpenAI()\n",
        "\n",
        "    # Split into batches of 50\n",
        "    batch_size = 50\n",
        "    total_batches = (len(chunks) + batch_size - 1) // batch_size\n",
        "\n",
        "    for i in range(0, len(chunks), batch_size):\n",
        "        batch = chunks[i:i + batch_size]\n",
        "        batch_num = i // batch_size + 1\n",
        "        print(f\"   Processing batch {batch_num} of {total_batches}...\")\n",
        "\n",
        "        contents = [chunk['content'] for chunk in batch]\n",
        "        \n",
        "        # Embed batch\n",
        "        response = client.embeddings.create(\n",
        "            model=model,\n",
        "            input=contents\n",
        "        )\n",
        "        \n",
        "        # Add embeddings to chunks\n",
        "        for j, chunk in enumerate(batch):\n",
        "            chunk['embedding'] = response.data[j].embedding\n",
        "\n",
        "        # Small delay to respect rate limits\n",
        "        if i + batch_size < len(chunks):\n",
        "                time.sleep(0.6) # Adjust as needed\n",
        "    \n",
        "    print(f\"Created {len(chunks)} embeddings\\n\")\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "771f03d6",
      "metadata": {},
      "source": [
        "### Table Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ed7484",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stage2_create_embeddings(json_file):\n",
        "    \"\"\"\n",
        "    Load extracted tables from JSON and create embeddings.\n",
        "    This is where you spend OpenAI tokens.\n",
        "    \"\"\"\n",
        "    load_dotenv()\n",
        "    \n",
        "    DATA_DIR = \"00-data\"\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "    print(\"STAGE 2: CREATING EMBEDDINGS\")\n",
        "    print(\"=\"*80)\n",
        "    print()\n",
        "    \n",
        "    # Load the extracted tables\n",
        "    print(f\"Loading: {json_file}\")\n",
        "    with open(json_file, 'r') as f:\n",
        "        table_chunks = json.load(f)\n",
        "    \n",
        "    print(f\"Loaded {len(table_chunks)} tables\")\n",
        "    \n",
        "    print(\"\\nCreating embeddings...\")\n",
        "    embedded_chunks = create_embeddings(table_chunks)\n",
        "    \n",
        "    print(\"\\nStoring in FAISS...\")\n",
        "    faiss_index = store_in_faiss(\n",
        "        embedded_chunks,\n",
        "        faiss_index_path=f\"{DATA_DIR}/base/faiss_table_index\"\n",
        "    )\n",
        "    \n",
        "    print(\"\\nSaving metadata...\")\n",
        "    save_metadata_mapping(\n",
        "        embedded_chunks,\n",
        "        mapping_path=f\"{DATA_DIR}/base/faiss_table_metadata.json\"\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"COMPLETE!\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"FAISS index: {DATA_DIR}/base/faiss_table_index\")\n",
        "    print(f\"Metadata: {DATA_DIR}/base/faiss_table_metadata.json\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03435447",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert table ingestion code here\n",
        "stage1_extract_and_save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad03ce98",
      "metadata": {},
      "outputs": [],
      "source": [
        "stage2_create_embeddings(f\"{DATA_DIR}/extracted_tables.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48c69c03",
      "metadata": {},
      "source": [
        "### Slides Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab5b53ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_slides_fitz(pdf_path, output_dir, lower_crop_extra=200):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    pdf = fitz.open(pdf_path)\n",
        "    print(f\"[INFO] Loaded '{pdf_path}' with {len(pdf)} pages.\")\n",
        "\n",
        "    for i, page in enumerate(pdf, start=1):\n",
        "        pix = page.get_pixmap(dpi=200)\n",
        "        img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
        "\n",
        "        # Crop lower for slides 1–2\n",
        "        if i in [1, 2]:\n",
        "            w, h = img.size\n",
        "            crop_box = (0, 0, w, min(h + lower_crop_extra, h))\n",
        "            img = img.crop(crop_box)\n",
        "\n",
        "        img.save(os.path.join(output_dir, f\"slide_{i:02d}.png\"), \"PNG\")\n",
        "\n",
        "    print(f\"Extracted {len(pdf)} slides from {pdf_path}\")\n",
        "\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "def ocr_folder(folder, label):\n",
        "    docs = []\n",
        "    for fname in sorted(os.listdir(folder)):\n",
        "        if fname.endswith(\".png\"):\n",
        "            path = os.path.join(folder, fname)\n",
        "            text = pytesseract.image_to_string(Image.open(path))\n",
        "            if text.strip():\n",
        "                docs.append(Document(\n",
        "                    page_content=text,\n",
        "                    metadata={\"image_path\": path, \"source_report\": label}\n",
        "                ))\n",
        "    return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1ec3457",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract slides and OCR\n",
        "pdf_path = []\n",
        "for folder in [\"presentations\"]:\n",
        "    files = glob.glob(f\"{DATA_DIR}/{folder}/*.pdf\")\n",
        "    pdf_path.extend(files)\n",
        "\n",
        "print(f\"Processing {len(pdf_path)} PDFs from all folders\")\n",
        "\n",
        "docs = []\n",
        "for pdf in pdf_path:\n",
        "    # Create output folder based on PDF name\n",
        "    pdf_name = os.path.splitext(os.path.basename(pdf))[0]\n",
        "    slide_folder = f\"{DATA_DIR}/presentations/slides_{pdf_name}\"\n",
        "    \n",
        "    print(f\"Extracting slides from {pdf_name}...\")\n",
        "    extract_slides_fitz(pdf, slide_folder)\n",
        "    \n",
        "    # OCR the extracted slides\n",
        "    pdf_docs = ocr_folder(slide_folder, pdf_name)\n",
        "    docs.extend(pdf_docs)\n",
        "\n",
        "print(f\"Loaded {len(docs)} slide documents from {len(pdf_path)} PDFs.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24871dad",
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the json file\n",
        "with open(f\"{DATA_DIR}/test.json\", \"r\") as f:\n",
        "    doc = json.load(f)\n",
        "\n",
        "chunks = []\n",
        "\n",
        "for fileDoc , docContent in doc.items():\n",
        "    for page_num, content in docContent.items():\n",
        "        page_section = content.get(\"page_section\", \"unknown\")\n",
        "        text = content.get(\"text\", \"\")\n",
        "        tables = content.get(\"tables\", [])\n",
        "\n",
        "        if text.strip():\n",
        "            chunks.append({\n",
        "                \"id\": f\"{fileDoc}-page-{page_num}-text\",\n",
        "                \"text\": f\"Financial filing text section: {text}\",\n",
        "                \"metadata\": {\"document\": fileDoc, \"page_number\": page_num, \"page_section\": page_section, \"chunk_type\": \"prose\"}\n",
        "            })\n",
        "\n",
        "print(f\"Created {len(chunks)} chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bd37aab",
      "metadata": {},
      "outputs": [],
      "source": [
        "text = [ chunk[\"text\"] for chunk in chunks ]\n",
        "\n",
        "embeddings = embed_text_passage (text)\n",
        "\n",
        "print (f\"Embeddings shape: {embeddings.shape}\")\n",
        "\n",
        "# Create a FAISS index - IP for normalized embeddings\n",
        "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "print (f\"FAISS index contains {index.ntotal} vectors.\")\n",
        "\n",
        "# save it locally\n",
        "output_dir = f\"{DATA_DIR}/base\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# storing the index\n",
        "faiss.write_index(index, f\"{output_dir}/base.faiss\")\n",
        "print(f\"Index saved to {output_dir}/base.faiss\")\n",
        "\n",
        "# store the chunks\n",
        "with open(f\"{DATA_DIR}/base/chunks.json\", \"w\") as f:\n",
        "    json.dump(chunks, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ffb05fc",
      "metadata": {
        "id": "6ffb05fc"
      },
      "source": [
        "## 4. Baseline Pipeline\n",
        "\n",
        "**Baseline (starting point)**\n",
        "*   Naive chunking.\n",
        "*   Single-pass vector search.\n",
        "*   One LLM call, no caching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540b7020",
      "metadata": {
        "id": "540b7020"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement baseline retrieval + generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e9e3ea",
      "metadata": {
        "id": "01e9e3ea"
      },
      "source": [
        "## 5. Benchmark Runner\n",
        "\n",
        "Run these 3 standardized queries. Produce JSON then prose answers with citations. These are the standardized queries.\n",
        "\n",
        "*   Gross Margin Trend (or NIM if Bank)\n",
        "    *   Query: \"Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\"\n",
        "    *   Expected Output: A quarterly table of Gross Margin % (or NIM % if bank).\n",
        "\n",
        "*   Operating Expenses (Opex) YoY for 3 Years\n",
        "    *   Query: \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
        "    *   Expected Output: A 3-year Opex table (absolute numbers and % change).\n",
        "\n",
        "*   Operating Efficiency Ratio\n",
        "    *   Query: \"Calculate the Operating Efficiency Ratio (Opex ÷ Operating Income) for the last 3 fiscal years, showing the working.\"\n",
        "    *   Expected Output: Table with Opex, Operating Income, and calculated ratio for 3 years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7bddc40",
      "metadata": {
        "id": "e7bddc40"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement benchmark runner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683ebeda",
      "metadata": {
        "id": "683ebeda"
      },
      "source": [
        "## 6. Instrumentation\n",
        "\n",
        "Log timings: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total. Log tokens, cache hits, tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5425de5",
      "metadata": {
        "id": "d5425de5"
      },
      "outputs": [],
      "source": [
        "# Example instrumentation schema\n",
        "import pandas as pd\n",
        "logs = pd.DataFrame(columns=['Query','T_ingest','T_retrieve','T_rerank','T_reason','T_generate','T_total','Tokens','CacheHits','Tools'])\n",
        "logs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c01bf4",
      "metadata": {
        "id": "e8c01bf4"
      },
      "source": [
        "## 7. Optimizations\n",
        "\n",
        "**Required Optimizations**\n",
        "\n",
        "Each team must implement at least:\n",
        "*   2 retrieval optimizations (e.g., hybrid BM25+vector, smaller embeddings, dynamic k).\n",
        "*   1 caching optimization (query cache or ratio cache).\n",
        "*   1 agentic optimization (plan pruning, parallel sub-queries).\n",
        "*   1 system optimization (async I/O, batch embedding, memory-mapped vectors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783f0e2e",
      "metadata": {
        "id": "783f0e2e"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement optimizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5894d19a",
      "metadata": {},
      "source": [
        "### Table Agentic Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e126e8d6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running agent query...\n",
            "\n",
            "\n",
            "============================================================\n",
            "QUERY: Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\n",
            "============================================================\n",
            "\n",
            "Cache MISS. Proceeding with retrieval...\n",
            "\n",
            "PLANNING PHASE\n",
            "------------------------------------------------------------\n",
            "Query Type: comparison\n",
            "Metrics Needed: Operating Expenses 2023, Operating Expenses 2024, Operating Expenses 2025\n",
            "Planned Searches: 3\n",
            "  1. [tables] Operating Expenses 2023\n",
            "     Reason: To retrieve structured financial data for accurate year-on-year comparison.\n",
            "  2. [tables] Operating Expenses 2024\n",
            "     Reason: To retrieve structured financial data for accurate year-on-year comparison.\n",
            "  3. [tables] Operating Expenses 2025\n",
            "     Reason: To retrieve structured financial data for accurate year-on-year comparison.\n",
            "\n",
            "RETRIEVAL PHASE\n",
            "------------------------------------------------------------\n",
            "\n",
            "Total chunks retrieved: 15\n",
            "Unique chunks: 9\n",
            "\n",
            "GENERATE ANSWER PHASE\n",
            "------------------------------------------------------------\n",
            "Answer generated: 1760 characters\n",
            "\n",
            "Cache storage completed in 0.0000 seconds.\n",
            "\n",
            "====================== ANSWER ======================\n",
            "To show the Operating Expenses for the last three fiscal years and provide a year-on-year comparison, we will focus on the General and Administrative (G&A) expenses as a proxy for operating expenses, as this is the data available. Here is the data extracted from the provided documents:\n",
            "\n",
            "### General and Administrative Expenses (in millions)\n",
            "\n",
            "| Year | G&A Expenses | Source                  |\n",
            "|------|--------------|-------------------------|\n",
            "| 2021 | $13,510      | (Source: goog-10-k-2022)|\n",
            "| 2022 | $15,724      | (Source: goog-10-k-2023)|\n",
            "| 2023 | $16,425      | (Source: goog-10-k-2024)|\n",
            "\n",
            "### Year-on-Year Comparison\n",
            "\n",
            "1. **2021 to 2022:**\n",
            "   - **Calculation:** \n",
            "     \\[\n",
            "     \\text{Percentage Increase} = \\left(\\frac{15,724 - 13,510}{13,510}\\right) \\times 100 = 16.39\\%\n",
            "     \\]\n",
            "   - **Implication:** There was a 16.39% increase in G&A expenses from 2021 to 2022, indicating a significant rise in operating costs.\n",
            "\n",
            "2. **2022 to 2023:**\n",
            "   - **Calculation:** \n",
            "     \\[\n",
            "     \\text{Percentage Increase} = \\left(\\frac{16,425 - 15,724}{15,724}\\right) \\times 100 = 4.46\\%\n",
            "     \\]\n",
            "   - **Implication:** The G&A expenses increased by 4.46% from 2022 to 2023, showing a continued rise in operating expenses, albeit at a slower rate compared to the previous year.\n",
            "\n",
            "### Summary\n",
            "- The G&A expenses have consistently increased over the past three years.\n",
            "- The growth rate of these expenses slowed down from 16.39% in 2021-2022 to 4.46% in 2022-2023.\n",
            "- This trend suggests that while operating costs are still rising, the company may be implementing measures to control the rate of increase.\n",
            "\n",
            "This analysis is based on the data provided in the retrieved documents, specifically focusing on the General and Administrative expenses as a representation of operating expenses.\n",
            "===================================================\n",
            "\n",
            "Sources: ['goog-10-q-q1-2024', 'goog-10-q-q2-2025', 'goog-10-k-2023-final', 'goog-10-k-2022', 'goog-10-k-2024', 'goog-10-q-q2-2024', 'goog-10-q-q1-2023', 'goog-10-q-q3-2022', 'goog-10-q-q1-2025']\n"
          ]
        }
      ],
      "source": [
        "FAISS_INDEX = f\"{DATA_DIR}/base/faiss_table_index\"\n",
        "METADATA_JSON = f\"{DATA_DIR}/base/faiss_table_metadata.json\"\n",
        "\n",
        "# Create the agent\n",
        "table_agent = TableAgenticRAG(\n",
        "    faiss_index_path=FAISS_INDEX,\n",
        "    metadata_json_path=METADATA_JSON\n",
        ")\n",
        "\n",
        "query = \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
        "\n",
        "\n",
        "print(\"\\nRunning agent query...\\n\")\n",
        "result = table_agent.query(query, verbose=True)\n",
        "\n",
        "\n",
        "print(\"\\n====================== ANSWER ======================\")\n",
        "print(result[\"answer\"])\n",
        "print(\"===================================================\\n\")\n",
        "\n",
        "\n",
        "print(\"Sources:\", result[\"sources\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "86b9f1f2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running agent query 2...\n",
            "\n",
            "\n",
            "============================================================\n",
            "QUERY: What is the operating expense for the last 3 fiscal years, year-on-year comparison.\n",
            "============================================================\n",
            "\n",
            "Cache HIT:\n",
            "  Similarity: 0.9032\n",
            "  Cached Query: Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\n",
            "\n",
            "\n",
            "====================== ANSWER ======================\n",
            "To show the Operating Expenses for the last three fiscal years and provide a year-on-year comparison, we will focus on the General and Administrative (G&A) expenses as a proxy for operating expenses, as this is the data available. Here is the data extracted from the provided documents:\n",
            "\n",
            "### General and Administrative Expenses (in millions)\n",
            "\n",
            "| Year | G&A Expenses | Source                  |\n",
            "|------|--------------|-------------------------|\n",
            "| 2021 | $13,510      | (Source: goog-10-k-2022)|\n",
            "| 2022 | $15,724      | (Source: goog-10-k-2023)|\n",
            "| 2023 | $16,425      | (Source: goog-10-k-2024)|\n",
            "\n",
            "### Year-on-Year Comparison\n",
            "\n",
            "1. **2021 to 2022:**\n",
            "   - **Calculation:** \n",
            "     \\[\n",
            "     \\text{Percentage Increase} = \\left(\\frac{15,724 - 13,510}{13,510}\\right) \\times 100 = 16.39\\%\n",
            "     \\]\n",
            "   - **Implication:** There was a 16.39% increase in G&A expenses from 2021 to 2022, indicating a significant rise in operating costs.\n",
            "\n",
            "2. **2022 to 2023:**\n",
            "   - **Calculation:** \n",
            "     \\[\n",
            "     \\text{Percentage Increase} = \\left(\\frac{16,425 - 15,724}{15,724}\\right) \\times 100 = 4.46\\%\n",
            "     \\]\n",
            "   - **Implication:** The G&A expenses increased by 4.46% from 2022 to 2023, showing a continued rise in operating expenses, albeit at a slower rate compared to the previous year.\n",
            "\n",
            "### Summary\n",
            "- The G&A expenses have consistently increased over the past three years.\n",
            "- The growth rate of these expenses slowed down from 16.39% in 2021-2022 to 4.46% in 2022-2023.\n",
            "- This trend suggests that while operating costs are still rising, the company may be implementing measures to control the rate of increase.\n",
            "\n",
            "This analysis is based on the data provided in the retrieved documents, specifically focusing on the General and Administrative expenses as a representation of operating expenses.\n",
            "===================================================\n",
            "\n",
            "Sources: []\n"
          ]
        }
      ],
      "source": [
        "query2 = \"What is the operating expense for the last 3 fiscal years, year-on-year comparison.\"\n",
        "print(\"\\nRunning agent query 2...\\n\")\n",
        "result = table_agent.query(query2, verbose=True)\n",
        "\n",
        "print(\"\\n====================== ANSWER ======================\")\n",
        "print(result[\"answer\"])\n",
        "print(\"===================================================\\n\")\n",
        "\n",
        "\n",
        "print(\"Sources:\", result[\"sources\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a91ce833",
      "metadata": {
        "id": "a91ce833"
      },
      "source": [
        "## 8. Results & Plots\n",
        "\n",
        "Show baseline vs optimized. Include latency plots (p50/p95) and accuracy tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96550f3",
      "metadata": {
        "id": "d96550f3"
      },
      "outputs": [],
      "source": [
        "# TODO: Generate plots with matplotlib\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
